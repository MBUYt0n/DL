{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"shusrith/machine-trainslation\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106178</th>\n",
       "      <td>[2, 290, 2762, 1666, 369, 398, 778, 708, 265, ...</td>\n",
       "      <td>[2, 290, 302, 311, 1614, 265, 369, 986, 500, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23834</th>\n",
       "      <td>[2, 300, 3634, 449, 332, 1436, 224, 3, 0, 0, 0...</td>\n",
       "      <td>[2, 434, 1474, 918, 322, 321, 1800, 224, 3, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111637</th>\n",
       "      <td>[2, 657, 304, 1820, 4414, 328, 426, 404, 334, ...</td>\n",
       "      <td>[2, 375, 22651, 4592, 294, 444, 336, 4106, 690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102138</th>\n",
       "      <td>[2, 805, 459, 304, 526, 382, 398, 871, 1251, 1...</td>\n",
       "      <td>[2, 879, 2687, 265, 2135, 321, 314, 1331, 9191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127930</th>\n",
       "      <td>[2, 300, 778, 304, 671, 300, 778, 304, 575, 70...</td>\n",
       "      <td>[2, 2798, 500, 9411, 500, 12706, 292, 500, 106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84833</th>\n",
       "      <td>[2, 290, 1401, 462, 7296, 1235, 224, 3, 0, 0, ...</td>\n",
       "      <td>[2, 1206, 290, 2763, 352, 7644, 224, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27872</th>\n",
       "      <td>[2, 300, 5408, 334, 4557, 224, 3, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 331, 5849, 393, 8476, 224, 3, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12382</th>\n",
       "      <td>[2, 555, 2701, 4037, 224, 3, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[2, 3403, 393, 5508, 224, 3, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84177</th>\n",
       "      <td>[2, 300, 1366, 272, 1055, 1024, 384, 3688, 224...</td>\n",
       "      <td>[2, 321, 1429, 571, 2728, 294, 290, 621, 5655,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115910</th>\n",
       "      <td>[2, 659, 575, 290, 572, 606, 270, 947, 1603, 2...</td>\n",
       "      <td>[2, 1339, 5800, 290, 2787, 294, 882, 349, 6486...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128982 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English  \\\n",
       "106178  [2, 290, 2762, 1666, 369, 398, 778, 708, 265, ...   \n",
       "23834   [2, 300, 3634, 449, 332, 1436, 224, 3, 0, 0, 0...   \n",
       "111637  [2, 657, 304, 1820, 4414, 328, 426, 404, 334, ...   \n",
       "102138  [2, 805, 459, 304, 526, 382, 398, 871, 1251, 1...   \n",
       "127930  [2, 300, 778, 304, 671, 300, 778, 304, 575, 70...   \n",
       "...                                                   ...   \n",
       "84833   [2, 290, 1401, 462, 7296, 1235, 224, 3, 0, 0, ...   \n",
       "27872   [2, 300, 5408, 334, 4557, 224, 3, 0, 0, 0, 0, ...   \n",
       "12382   [2, 555, 2701, 4037, 224, 3, 0, 0, 0, 0, 0, 0,...   \n",
       "84177   [2, 300, 1366, 272, 1055, 1024, 384, 3688, 224...   \n",
       "115910  [2, 659, 575, 290, 572, 606, 270, 947, 1603, 2...   \n",
       "\n",
       "                                                  Spanish  \n",
       "106178  [2, 290, 302, 311, 1614, 265, 369, 986, 500, 2...  \n",
       "23834   [2, 434, 1474, 918, 322, 321, 1800, 224, 3, 0,...  \n",
       "111637  [2, 375, 22651, 4592, 294, 444, 336, 4106, 690...  \n",
       "102138  [2, 879, 2687, 265, 2135, 321, 314, 1331, 9191...  \n",
       "127930  [2, 2798, 500, 9411, 500, 12706, 292, 500, 106...  \n",
       "...                                                   ...  \n",
       "84833   [2, 1206, 290, 2763, 352, 7644, 224, 3, 0, 0, ...  \n",
       "27872   [2, 331, 5849, 393, 8476, 224, 3, 0, 0, 0, 0, ...  \n",
       "12382   [2, 3403, 393, 5508, 224, 3, 0, 0, 0, 0, 0, 0,...  \n",
       "84177   [2, 321, 1429, 571, 2728, 294, 290, 621, 5655,...  \n",
       "115910  [2, 1339, 5800, 290, 2787, 294, 882, 349, 6486...  \n",
       "\n",
       "[128982 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv(f\"EnglishOrSpanish/output_joint1.csv\")\n",
    "df = shuffle(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106178</th>\n",
       "      <td>[2, 290, 2762, 1666, 369, 398, 778, 708, 265, ...</td>\n",
       "      <td>[2, 290, 302, 311, 1614, 265, 369, 986, 500, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23834</th>\n",
       "      <td>[2, 300, 3634, 449, 332, 1436, 224, 3, 0, 0, 0...</td>\n",
       "      <td>[2, 434, 1474, 918, 322, 321, 1800, 224, 3, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111637</th>\n",
       "      <td>[2, 657, 304, 1820, 4414, 328, 426, 404, 334, ...</td>\n",
       "      <td>[2, 375, 22651, 4592, 294, 444, 336, 4106, 690...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102138</th>\n",
       "      <td>[2, 805, 459, 304, 526, 382, 398, 871, 1251, 1...</td>\n",
       "      <td>[2, 879, 2687, 265, 2135, 321, 314, 1331, 9191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127930</th>\n",
       "      <td>[2, 300, 778, 304, 671, 300, 778, 304, 575, 70...</td>\n",
       "      <td>[2, 2798, 500, 9411, 500, 12706, 292, 500, 106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84833</th>\n",
       "      <td>[2, 290, 1401, 462, 7296, 1235, 224, 3, 0, 0, ...</td>\n",
       "      <td>[2, 1206, 290, 2763, 352, 7644, 224, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27872</th>\n",
       "      <td>[2, 300, 5408, 334, 4557, 224, 3, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 331, 5849, 393, 8476, 224, 3, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12382</th>\n",
       "      <td>[2, 555, 2701, 4037, 224, 3, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[2, 3403, 393, 5508, 224, 3, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84177</th>\n",
       "      <td>[2, 300, 1366, 272, 1055, 1024, 384, 3688, 224...</td>\n",
       "      <td>[2, 321, 1429, 571, 2728, 294, 290, 621, 5655,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115910</th>\n",
       "      <td>[2, 659, 575, 290, 572, 606, 270, 947, 1603, 2...</td>\n",
       "      <td>[2, 1339, 5800, 290, 2787, 294, 882, 349, 6486...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128982 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  English  \\\n",
       "106178  [2, 290, 2762, 1666, 369, 398, 778, 708, 265, ...   \n",
       "23834   [2, 300, 3634, 449, 332, 1436, 224, 3, 0, 0, 0...   \n",
       "111637  [2, 657, 304, 1820, 4414, 328, 426, 404, 334, ...   \n",
       "102138  [2, 805, 459, 304, 526, 382, 398, 871, 1251, 1...   \n",
       "127930  [2, 300, 778, 304, 671, 300, 778, 304, 575, 70...   \n",
       "...                                                   ...   \n",
       "84833   [2, 290, 1401, 462, 7296, 1235, 224, 3, 0, 0, ...   \n",
       "27872   [2, 300, 5408, 334, 4557, 224, 3, 0, 0, 0, 0, ...   \n",
       "12382   [2, 555, 2701, 4037, 224, 3, 0, 0, 0, 0, 0, 0,...   \n",
       "84177   [2, 300, 1366, 272, 1055, 1024, 384, 3688, 224...   \n",
       "115910  [2, 659, 575, 290, 572, 606, 270, 947, 1603, 2...   \n",
       "\n",
       "                                                  Spanish  \n",
       "106178  [2, 290, 302, 311, 1614, 265, 369, 986, 500, 2...  \n",
       "23834   [2, 434, 1474, 918, 322, 321, 1800, 224, 3, 0,...  \n",
       "111637  [2, 375, 22651, 4592, 294, 444, 336, 4106, 690...  \n",
       "102138  [2, 879, 2687, 265, 2135, 321, 314, 1331, 9191...  \n",
       "127930  [2, 2798, 500, 9411, 500, 12706, 292, 500, 106...  \n",
       "...                                                   ...  \n",
       "84833   [2, 1206, 290, 2763, 352, 7644, 224, 3, 0, 0, ...  \n",
       "27872   [2, 331, 5849, 393, 8476, 224, 3, 0, 0, 0, 0, ...  \n",
       "12382   [2, 3403, 393, 5508, 224, 3, 0, 0, 0, 0, 0, 0,...  \n",
       "84177   [2, 321, 1429, 571, 2728, 294, 290, 621, 5655,...  \n",
       "115910  [2, 1339, 5800, 290, 2787, 294, 882, 349, 6486...  \n",
       "\n",
       "[128982 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df[\"English\"] = df[\"English\"].apply(ast.literal_eval)\n",
    "df[\"Spanish\"] = df[\"Spanish\"].apply(ast.literal_eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train = TensorDataset(\n",
    "    torch.tensor(df[\"English\"][:100000].tolist(), dtype=torch.long),\n",
    "    torch.tensor(df[\"Spanish\"][:100000].tolist(), dtype=torch.long),\n",
    ")\n",
    "test = TensorDataset(\n",
    "    torch.tensor(df[\"English\"][100000:].tolist(), dtype=torch.long),\n",
    "    torch.tensor(df[\"Spanish\"][100000:].tolist(), dtype=torch.long),\n",
    ")\n",
    "train_loader = DataLoader(train, batch_size=256, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size=256, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"EnglishOrSpanish/vocab.json\", \"r\") as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=4, dropout=0.3):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=14453)\n",
    "        self.lstm = nn.LSTM(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.hidden_norm = nn.LayerNorm(hidden_size)\n",
    "        self.cell_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.LSTM):\n",
    "            for name, param in module.named_parameters():\n",
    "                if \"weight\" in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif \"bias\" in name:\n",
    "                    nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        output = self.layer_norm(output)\n",
    "        hidden = self.hidden_norm(hidden)\n",
    "        cell = self.cell_norm(cell)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.attn = nn.Linear(hidden_size, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_output):\n",
    "        hidden = hidden.unsqueeze(1)\n",
    "        scores = self.attn(encoder_output)\n",
    "        scores = torch.tanh(scores + hidden)\n",
    "        attention = self.v(scores).squeeze(2)\n",
    "        return nn.functional.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, attention, num_layers=4, dropout=0.3):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size, padding_idx=23722)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            2 * hidden_size,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.attention = attention\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.hidden_norm = nn.LayerNorm(hidden_size)\n",
    "        self.cell_norm = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.LSTM):\n",
    "            for name, param in module.named_parameters():\n",
    "                if \"weight\" in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif \"bias\" in name:\n",
    "                    nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x, hidden, cell, encoder_output):\n",
    "        attention_scores = self.attention(hidden[-1], encoder_output)\n",
    "        context = torch.bmm(attention_scores.unsqueeze(1), encoder_output)\n",
    "        embedded = self.dropout(self.embedding(x)).unsqueeze(1)\n",
    "        embedded = torch.cat([embedded, context], dim=2)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        output = self.layer_norm(output)\n",
    "        hidden = self.hidden_norm(hidden)\n",
    "        cell = self.cell_norm(cell)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq:\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.vocab_size = self.decoder.vocab_size\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        enc_optimizer,\n",
    "        dec_optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        encoder_scheduler,\n",
    "        decoder_scheduler,\n",
    "        num_epochs,\n",
    "    ):\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            self.encoder.train()\n",
    "            self.decoder.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "            for src, trg in progress_bar:\n",
    "                src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "                batch_size, trg_len = trg.shape\n",
    "\n",
    "                enc_optimizer.zero_grad()\n",
    "                dec_optimizer.zero_grad()\n",
    "\n",
    "                encoder_out, hidden, cell = self.encoder(src)\n",
    "                outputs = torch.zeros(batch_size, trg_len, self.vocab_size).to(\n",
    "                    self.device\n",
    "                )\n",
    "                x = trg[:, 0]\n",
    "                for t in range(1, trg_len):\n",
    "                    output, hidden, cell = self.decoder(x, hidden, cell, encoder_out)\n",
    "                    outputs[:, t, :] = output.squeeze(1)\n",
    "                    teacher_force = torch.rand(1).item() < self.teacher_forcing_ratio\n",
    "                    x = trg[:, t] if teacher_force else output.argmax(dim=1)\n",
    "                loss = criterion(\n",
    "                    outputs[:, 1:].reshape(-1, self.vocab_size), trg[:, 1:].reshape(-1)\n",
    "                )\n",
    "                loss.backward()\n",
    "                enc_optimizer.step()\n",
    "                dec_optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                preds = outputs.argmax(dim=2)\n",
    "                correct = (preds == trg).float().sum().item()\n",
    "                total = trg.numel()\n",
    "                batch_acc = correct / total\n",
    "                epoch_acc += batch_acc\n",
    "\n",
    "                progress_bar.set_postfix(\n",
    "                    loss=f\"{loss.item():.4f}\", acc=f\"{batch_acc:.4f}\"\n",
    "                )\n",
    "\n",
    "            train_loss = epoch_loss / len(train_loader)\n",
    "            train_acc = epoch_acc / len(train_loader)\n",
    "\n",
    "            # ---------------- VALIDATION ---------------- #\n",
    "            self.encoder.eval()\n",
    "            self.decoder.eval()\n",
    "            val_epoch_loss = 0\n",
    "            val_epoch_acc = 0\n",
    "            progress_bar = tqdm(test_loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for src, trg in progress_bar:\n",
    "                    src, trg = src.to(device), trg.to(device)\n",
    "                    batch_size, trg_len = trg.shape\n",
    "                    encoder_out, hidden, cell = self.encoder(src)\n",
    "                    outputs = torch.zeros(batch_size, trg_len, self.vocab_size).to(\n",
    "                        self.device\n",
    "                    )\n",
    "                    x = trg[:, 0]\n",
    "                    for t in range(1, trg_len):\n",
    "                        output, hidden, cell = self.decoder(x, hidden, cell, encoder_out)\n",
    "                        outputs[:, t, :] = output\n",
    "                        x = output.argmax(dim=1)\n",
    "\n",
    "                    loss = criterion(\n",
    "                        outputs[:, 1:].reshape(-1, self.vocab_size),\n",
    "                        trg[:, 1:].reshape(-1),\n",
    "                    )\n",
    "                    val_epoch_loss += loss.item()\n",
    "\n",
    "                    preds = outputs.argmax(dim=2)\n",
    "                    correct = (preds == trg).float().sum().item()\n",
    "                    total = trg.numel()\n",
    "                    batch_acc = correct / total\n",
    "                    val_epoch_acc += batch_acc\n",
    "\n",
    "                    progress_bar.set_postfix(\n",
    "                        loss=f\"{loss.item():.4f}\", acc=f\"{batch_acc:.4f}\"\n",
    "                    )\n",
    "\n",
    "            val_loss = val_epoch_loss / len(test_loader)\n",
    "            val_acc = val_epoch_acc / len(test_loader)\n",
    "            print(\n",
    "                f\"Train loss : {train_loss}, Train accuracy : {train_acc}, Val_loss : {val_loss}, val accuracy : {val_acc}\"\n",
    "            )\n",
    "            encoder_scheduler.step(val_loss)\n",
    "            decoder_scheduler.step(val_loss)\n",
    "        return train_loss, train_acc, val_loss, val_acc\n",
    "\n",
    "    def predict(self, src, trg):\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            src, trg = src.to(self.device), trg.to(self.device)\n",
    "            batch_size, trg_len = trg.shape\n",
    "            _, hidden, cell = self.encoder(src)\n",
    "            outputs = torch.zeros(batch_size, trg_len, self.vocab_size).to(self.device)\n",
    "            x = trg[:, 0]\n",
    "            for t in range(1, trg_len):\n",
    "                output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "                outputs[:, t, :] = output\n",
    "                x = output.argmax(dim=1)\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "hidden_size = 128\n",
    "encoder = Encoder(vocab_size, hidden_size).to(device)\n",
    "attention = Attention(hidden_size)\n",
    "decoder = Decoder(vocab_size, hidden_size, attention).to(device)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device, 0.5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=23722)\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "encoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    encoder_optimizer, mode=\"min\", factor=0.9, patience=2\n",
    ")\n",
    "decoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    decoder_optimizer, mode=\"min\", factor=0.9, patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.09 GiB. GPU 0 has a total capacity of 5.76 GiB of which 434.75 MiB is free. Including non-PyTorch memory, this process has 5.33 GiB memory in use. Of the allocated memory 5.20 GiB is allocated by PyTorch, and 23.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 5\u001b[0m \u001b[43mseq2seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m, in \u001b[0;36mSeq2Seq.train\u001b[0;34m(self, train_loader, test_loader, enc_optimizer, dec_optimizer, criterion, device, encoder_scheduler, decoder_scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m trg[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, trg_len):\n\u001b[0;32m---> 44\u001b[0m     output, hidden, cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     outputs[:, t, :] \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     46\u001b[0m     teacher_force \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteacher_forcing_ratio\n",
      "File \u001b[0;32m~/projects/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, hidden, cell, encoder_output)\u001b[0m\n\u001b[1;32m     40\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], encoder_output)\n\u001b[1;32m     41\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(attention_scores\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), encoder_output)\n\u001b[0;32m---> 42\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m embedded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([embedded, context], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     44\u001b[0m output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(embedded, (hidden, cell))\n",
      "File \u001b[0;32m~/projects/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/projects/torch/lib/python3.12/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/torch/lib/python3.12/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.09 GiB. GPU 0 has a total capacity of 5.76 GiB of which 434.75 MiB is free. Including non-PyTorch memory, this process has 5.33 GiB memory in use. Of the allocated memory 5.20 GiB is allocated by PyTorch, and 23.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "seq2seq.train(\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    encoder_optimizer,\n",
    "    decoder_optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    encoder_scheduler,\n",
    "    decoder_scheduler,\n",
    "    20,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
