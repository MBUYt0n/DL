{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cb791c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:03.641178Z",
     "iopub.status.busy": "2025-03-22T08:33:03.640949Z",
     "iopub.status.idle": "2025-03-22T08:33:04.068920Z",
     "shell.execute_reply": "2025-03-22T08:33:04.068022Z"
    },
    "papermill": {
     "duration": 0.434136,
     "end_time": "2025-03-22T08:33:04.070215",
     "exception": false,
     "start_time": "2025-03-22T08:33:03.636079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"shusrith/machine-trainslation\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "452960d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:04.078715Z",
     "iopub.status.busy": "2025-03-22T08:33:04.078435Z",
     "iopub.status.idle": "2025-03-22T08:33:06.101549Z",
     "shell.execute_reply": "2025-03-22T08:33:06.100812Z"
    },
    "id": "ZjgPhK4yAU3W",
    "outputId": "4ab7d36a-ce19-4580-9eee-bcf62a2d3bfe",
    "papermill": {
     "duration": 2.028917,
     "end_time": "2025-03-22T08:33:06.103063",
     "exception": false,
     "start_time": "2025-03-22T08:33:04.074146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12646</th>\n",
       "      <td>[2, 744, 700, 606, 224, 3, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[2, 387, 636, 3573, 627, 224, 3, 0, 0, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41508</th>\n",
       "      <td>[2, 1638, 1598, 398, 304, 224, 3, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 1420, 918, 2526, 224, 3, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>[2, 1823, 272, 290, 224, 3, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 5328, 265, 290, 224, 3, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95584</th>\n",
       "      <td>[2, 270, 2038, 356, 1632, 272, 572, 304, 265, ...</td>\n",
       "      <td>[2, 265, 349, 950, 665, 15003, 323, 14194, 224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72045</th>\n",
       "      <td>[2, 7832, 13583, 437, 300, 1366, 224, 3, 0, 0,...</td>\n",
       "      <td>[2, 3428, 284, 265, 321, 1429, 224, 3, 0, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14008</th>\n",
       "      <td>[2, 448, 2408, 334, 2246, 224, 3, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 886, 321, 2834, 17753, 883, 6337, 224, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37021</th>\n",
       "      <td>[2, 404, 334, 14295, 8359, 224, 3, 0, 0, 0, 0,...</td>\n",
       "      <td>[2, 690, 302, 590, 331, 4757, 3508, 224, 3, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77830</th>\n",
       "      <td>[2, 304, 803, 1430, 332, 272, 7519, 224, 3, 0,...</td>\n",
       "      <td>[2, 960, 831, 22894, 265, 321, 7205, 224, 3, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37688</th>\n",
       "      <td>[2, 395, 595, 930, 18319, 224, 3, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 6361, 5236, 16994, 224, 3, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12477</th>\n",
       "      <td>[2, 1111, 382, 3759, 224, 3, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[2, 5153, 265, 4450, 224, 3, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128982 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 English  \\\n",
       "12646  [2, 744, 700, 606, 224, 3, 0, 0, 0, 0, 0, 0, 0...   \n",
       "41508  [2, 1638, 1598, 398, 304, 224, 3, 0, 0, 0, 0, ...   \n",
       "5372   [2, 1823, 272, 290, 224, 3, 0, 0, 0, 0, 0, 0, ...   \n",
       "95584  [2, 270, 2038, 356, 1632, 272, 572, 304, 265, ...   \n",
       "72045  [2, 7832, 13583, 437, 300, 1366, 224, 3, 0, 0,...   \n",
       "...                                                  ...   \n",
       "14008  [2, 448, 2408, 334, 2246, 224, 3, 0, 0, 0, 0, ...   \n",
       "37021  [2, 404, 334, 14295, 8359, 224, 3, 0, 0, 0, 0,...   \n",
       "77830  [2, 304, 803, 1430, 332, 272, 7519, 224, 3, 0,...   \n",
       "37688  [2, 395, 595, 930, 18319, 224, 3, 0, 0, 0, 0, ...   \n",
       "12477  [2, 1111, 382, 3759, 224, 3, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                                 Spanish  \n",
       "12646  [2, 387, 636, 3573, 627, 224, 3, 0, 0, 0, 0, 0...  \n",
       "41508  [2, 1420, 918, 2526, 224, 3, 0, 0, 0, 0, 0, 0,...  \n",
       "5372   [2, 5328, 265, 290, 224, 3, 0, 0, 0, 0, 0, 0, ...  \n",
       "95584  [2, 265, 349, 950, 665, 15003, 323, 14194, 224...  \n",
       "72045  [2, 3428, 284, 265, 321, 1429, 224, 3, 0, 0, 0...  \n",
       "...                                                  ...  \n",
       "14008  [2, 886, 321, 2834, 17753, 883, 6337, 224, 3, ...  \n",
       "37021  [2, 690, 302, 590, 331, 4757, 3508, 224, 3, 0,...  \n",
       "77830  [2, 960, 831, 22894, 265, 321, 7205, 224, 3, 0...  \n",
       "37688  [2, 6361, 5236, 16994, 224, 3, 0, 0, 0, 0, 0, ...  \n",
       "12477  [2, 5153, 265, 4450, 224, 3, 0, 0, 0, 0, 0, 0,...  \n",
       "\n",
       "[128982 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv(f\"EnglishOrSpanish/output_joint1.csv\")\n",
    "df = shuffle(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749342f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:06.112927Z",
     "iopub.status.busy": "2025-03-22T08:33:06.112663Z",
     "iopub.status.idle": "2025-03-22T08:33:13.903769Z",
     "shell.execute_reply": "2025-03-22T08:33:13.902890Z"
    },
    "id": "3l1WLpiLAU3W",
    "outputId": "01736df9-0470-48b7-cad1-3f67d4934b66",
    "papermill": {
     "duration": 7.797798,
     "end_time": "2025-03-22T08:33:13.905172",
     "exception": false,
     "start_time": "2025-03-22T08:33:06.107374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df[\"English\"] = df[\"English\"].apply(ast.literal_eval)\n",
    "df[\"Spanish\"] = df[\"Spanish\"].apply(ast.literal_eval)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e57664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:13.913838Z",
     "iopub.status.busy": "2025-03-22T08:33:13.913610Z",
     "iopub.status.idle": "2025-03-22T08:33:17.462804Z",
     "shell.execute_reply": "2025-03-22T08:33:17.462115Z"
    },
    "id": "p8fPYQBWAU3X",
    "papermill": {
     "duration": 3.555074,
     "end_time": "2025-03-22T08:33:17.464352",
     "exception": false,
     "start_time": "2025-03-22T08:33:13.909278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_data = TensorDataset(\n",
    "    torch.tensor(df[\"English\"][:100000].tolist(), dtype=torch.long),\n",
    "    torch.tensor(df[\"Spanish\"][:100000].tolist(), dtype=torch.long),\n",
    ")\n",
    "test_data = TensorDataset(\n",
    "    torch.tensor(df[\"English\"][100000:].tolist(), dtype=torch.long),\n",
    "    torch.tensor(df[\"Spanish\"][100000:].tolist(), dtype=torch.long),\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c909238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:17.473267Z",
     "iopub.status.busy": "2025-03-22T08:33:17.472900Z",
     "iopub.status.idle": "2025-03-22T08:33:17.505118Z",
     "shell.execute_reply": "2025-03-22T08:33:17.504544Z"
    },
    "id": "_9tn5YdUAU3X",
    "papermill": {
     "duration": 0.037676,
     "end_time": "2025-03-22T08:33:17.506191",
     "exception": false,
     "start_time": "2025-03-22T08:33:17.468515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(f\"EnglishOrSpanish/vocab.json\", \"r\") as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447b98e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:17.514533Z",
     "iopub.status.busy": "2025-03-22T08:33:17.514276Z",
     "iopub.status.idle": "2025-03-22T08:33:17.519538Z",
     "shell.execute_reply": "2025-03-22T08:33:17.518960Z"
    },
    "id": "KIMlq-cdAU3Y",
    "papermill": {
     "duration": 0.010536,
     "end_time": "2025-03-22T08:33:17.520630",
     "exception": false,
     "start_time": "2025-03-22T08:33:17.510094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim, hidden_size, num_layers=2, dropout=0.3\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.LSTM):\n",
    "            for name, param in module.named_parameters():\n",
    "                if \"weight\" in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif \"bias\" in name:\n",
    "                    nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cca2e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:17.528599Z",
     "iopub.status.busy": "2025-03-22T08:33:17.528355Z",
     "iopub.status.idle": "2025-03-22T08:33:17.532832Z",
     "shell.execute_reply": "2025-03-22T08:33:17.532212Z"
    },
    "id": "7MEXFtjhAU3Y",
    "papermill": {
     "duration": 0.00976,
     "end_time": "2025-03-22T08:33:17.534001",
     "exception": false,
     "start_time": "2025-03-22T08:33:17.524241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.W1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W2 = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, enc_out):\n",
    "        hidden = hidden.unsqueeze(1)\n",
    "        score = self.v(torch.tanh(self.W1(hidden) + self.W2(enc_out)))\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        context_vector = torch.sum(attention_weights * enc_out, dim=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fcfc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:17.542159Z",
     "iopub.status.busy": "2025-03-22T08:33:17.541957Z",
     "iopub.status.idle": "2025-03-22T08:33:17.547997Z",
     "shell.execute_reply": "2025-03-22T08:33:17.547405Z"
    },
    "id": "B-kd_lvxAU3Y",
    "papermill": {
     "duration": 0.011398,
     "end_time": "2025-03-22T08:33:17.549178",
     "exception": false,
     "start_time": "2025-03-22T08:33:17.537780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim, hidden_size, num_layers=2, dropout=0.3\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim + hidden_size * 2,\n",
    "            hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.LSTM):\n",
    "            for name, param in module.named_parameters():\n",
    "                if \"weight\" in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif \"bias\" in name:\n",
    "                    nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x, hidden, cell, enc_out):\n",
    "        attention_vector, _ = self.attention(hidden[0], enc_out)\n",
    "        x = self.embedding(x)\n",
    "        x = torch.cat((attention_vector, x), dim=-1)\n",
    "        x = x.unsqueeze(1)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975efd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:17.557283Z",
     "iopub.status.busy": "2025-03-22T08:33:17.557085Z",
     "iopub.status.idle": "2025-03-22T08:33:17.563462Z",
     "shell.execute_reply": "2025-03-22T08:33:17.562864Z"
    },
    "id": "-pWuqe9Fvw4o",
    "papermill": {
     "duration": 0.011824,
     "end_time": "2025-03-22T08:33:17.564703",
     "exception": false,
     "start_time": "2025-03-22T08:33:17.552879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, vocab_size, teacher_forcing_ratio=0.5):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.vocab_size = vocab_size\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        enc_out, hidden, cell = self.encoder(src)\n",
    "        outputs = torch.zeros(trg.shape[0], trg.shape[1], self.decoder.vocab_size).to(\"cuda\")\n",
    "        x = trg[:, 0]\n",
    "        for t in range(1, trg.shape[1]):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell, enc_out)\n",
    "            output = output.squeeze(1)\n",
    "            outputs[:, t, :] = output\n",
    "            use_teacher_forcing = random.random() < self.teacher_forcing_ratio\n",
    "            x = trg[:, t] if use_teacher_forcing else output.argmax(dim=1)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def predict(self, src):\n",
    "        enc_out, hidden, cell = self.encoder(src)\n",
    "        outputs = torch.zeros(src.shape[0], src.shape[1], self.decoder.vocab_size).to(\"cuda\")\n",
    "        x = src[:, 0]\n",
    "        for i in range(1, src.shape[1]):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell, enc_out)\n",
    "            output = output.squeeze(1)\n",
    "            outputs[:, i, :] = output\n",
    "            x = output.argmax(dim=1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee5e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:17.573006Z",
     "iopub.status.busy": "2025-03-22T08:33:17.572809Z",
     "iopub.status.idle": "2025-03-22T08:33:28.576477Z",
     "shell.execute_reply": "2025-03-22T08:33:28.575803Z"
    },
    "id": "oZnO_wztAU3Y",
    "papermill": {
     "duration": 11.009511,
     "end_time": "2025-03-22T08:33:28.578034",
     "exception": false,
     "start_time": "2025-03-22T08:33:17.568523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        device,\n",
    "        scheduler, \n",
    "        num_epochs,\n",
    "    ):\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        model.encoder.train()\n",
    "        model.decoder.train()\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "        for src, trg in progress_bar:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(src, trg)\n",
    "            loss = criterion(\n",
    "                    outputs[:, 1:].reshape(-1, model.vocab_size), trg[:, 1:].reshape(-1)\n",
    "                )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                    loss=f\"{loss.item():.4f}\"\n",
    "                )\n",
    "\n",
    "        train_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "        # ---------------- VALIDATION ---------------- #\n",
    "        model.encoder.eval()\n",
    "        model.decoder.eval()\n",
    "        val_epoch_loss = 0\n",
    "        progress_bar = tqdm(test_loader, desc=\"Validating\", leave=False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for src, trg in progress_bar:\n",
    "                src, trg = src.to(device), trg.to(device)\n",
    "                outputs = model(src, trg)\n",
    "                loss = criterion(\n",
    "                        outputs[:, 1:].reshape(-1, model.vocab_size),\n",
    "                        trg[:, 1:].reshape(-1),\n",
    "                    )\n",
    "                val_epoch_loss += loss.item()\n",
    "\n",
    "                progress_bar.set_postfix(\n",
    "                        loss=f\"{loss.item():.4f}\"\n",
    "                    )\n",
    "\n",
    "        val_loss = val_epoch_loss / len(test_loader)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
    "        writer.add_scalar(\"Learning Rate\", scheduler.get_last_lr()[0], epoch)\n",
    "\n",
    "        print(\n",
    "            f\"Train loss : {train_loss}, Val_loss : {val_loss}, lr: {scheduler.get_last_lr()[0]}\"\n",
    "        )\n",
    "\n",
    "    writer.close()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1209626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:28.587034Z",
     "iopub.status.busy": "2025-03-22T08:33:28.586585Z",
     "iopub.status.idle": "2025-03-22T08:33:32.654256Z",
     "shell.execute_reply": "2025-03-22T08:33:32.653597Z"
    },
    "id": "rXj3XkiAAU3a",
    "papermill": {
     "duration": 4.073618,
     "end_time": "2025-03-22T08:33:32.655739",
     "exception": false,
     "start_time": "2025-03-22T08:33:28.582121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "hidden_size = 64\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "seq2seq = Seq2Seq(encoder, decoder, vocab_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(seq2seq.parameters(), lr=0.005, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbbb061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T08:33:32.664753Z",
     "iopub.status.busy": "2025-03-22T08:33:32.664259Z",
     "iopub.status.idle": "2025-03-22T13:39:55.700683Z",
     "shell.execute_reply": "2025-03-22T13:39:55.699901Z"
    },
    "id": "wsk2HEv5AU3a",
    "outputId": "3018e54b-2be5-411e-f471-b6f8e41ac256",
    "papermill": {
     "duration": 18383.042068,
     "end_time": "2025-03-22T13:39:55.701920",
     "exception": false,
     "start_time": "2025-03-22T08:33:32.659852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 5.460591206183801, Val_loss : 4.749622340750905, lr: 0.005\n",
      "\n",
      "Epoch 2/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseq2seq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, optimizer, criterion, device, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 33\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mset_postfix(\n\u001b[1;32m     36\u001b[0m             loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m         )\n\u001b[1;32m     39\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "train(\n",
    "    seq2seq,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    scheduler,\n",
    "    60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dee907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:39:58.699290Z",
     "iopub.status.busy": "2025-03-22T13:39:58.698987Z",
     "iopub.status.idle": "2025-03-22T13:39:59.033389Z",
     "shell.execute_reply": "2025-03-22T13:39:59.032657Z"
    },
    "id": "QcRGUFEp6EXC",
    "papermill": {
     "duration": 1.794293,
     "end_time": "2025-03-22T13:39:59.034902",
     "exception": false,
     "start_time": "2025-03-22T13:39:57.240609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(seq2seq.state_dict(), \"seq2seq-bidir-attention.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd90367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:40:01.838653Z",
     "iopub.status.busy": "2025-03-22T13:40:01.838299Z",
     "iopub.status.idle": "2025-03-22T13:40:02.120190Z",
     "shell.execute_reply": "2025-03-22T13:40:02.119433Z"
    },
    "papermill": {
     "duration": 1.733419,
     "end_time": "2025-03-22T13:40:02.121643",
     "exception": false,
     "start_time": "2025-03-22T13:40:00.388224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "hidden_size = 64\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_size).to(device)\n",
    "seq2seq = Seq2Seq(encoder, decoder, vocab_size).to(device)\n",
    "seq2seq.load_state_dict(torch.load(\"seq2seq-bidir-attention.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d7ea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:40:04.919840Z",
     "iopub.status.busy": "2025-03-22T13:40:04.919468Z",
     "iopub.status.idle": "2025-03-22T13:40:05.827035Z",
     "shell.execute_reply": "2025-03-22T13:40:05.826133Z"
    },
    "papermill": {
     "duration": 2.259685,
     "end_time": "2025-03-22T13:40:05.828388",
     "exception": false,
     "start_time": "2025-03-22T13:40:03.568703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 18])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.eval()\n",
    "# with torch.no_grad():\n",
    "a, b = next(iter(train_loader))\n",
    "a = a.to(device)\n",
    "b = b.to(device)\n",
    "with torch.no_grad():\n",
    "    x = seq2seq.predict(a)\n",
    "\n",
    "x = x.argmax(dim=2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ad5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:40:08.753801Z",
     "iopub.status.busy": "2025-03-22T13:40:08.753429Z",
     "iopub.status.idle": "2025-03-22T13:40:08.887051Z",
     "shell.execute_reply": "2025-03-22T13:40:08.886141Z"
    },
    "papermill": {
     "duration": 1.587873,
     "end_time": "2025-03-22T13:40:08.888724",
     "exception": false,
     "start_time": "2025-03-22T13:40:07.300851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    f\"EnglishOrSpanish/vocab.json\", f\"EnglishOrSpanish/merges.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ec26b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T13:40:11.712812Z",
     "iopub.status.busy": "2025-03-22T13:40:11.712376Z",
     "iopub.status.idle": "2025-03-22T13:40:11.719426Z",
     "shell.execute_reply": "2025-03-22T13:40:11.718517Z"
    },
    "papermill": {
     "duration": 1.388413,
     "end_time": "2025-03-22T13:40:11.720876",
     "exception": false,
     "start_time": "2025-03-22T13:40:10.332463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> qué tipo de chica es usted <EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<PAD> qué tipo de chica es <EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(b.tolist()[8]))\n",
    "print(tokenizer.decode(x.tolist()[8]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6838673,
     "sourceId": 11036243,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18437.638477,
   "end_time": "2025-03-22T13:40:18.678424",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-22T08:33:01.039947",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
