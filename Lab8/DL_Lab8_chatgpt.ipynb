{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 19:14:46.818953: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-23 19:14:46.827176: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742737486.837719   15724 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742737486.840707   15724 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-23 19:14:46.851232: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(x):\n",
    "    x = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", x)\n",
    "    return x.lower()\n",
    "\n",
    "\n",
    "def preproc_spanish(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9áéíóúüñÁÉÍÓÚÜÑ\\s]\", \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"spa.txt.csv\")\n",
    "df[\"English\"] = df[\"English\"].apply(preproc)\n",
    "df[\"Translated\"] = df[\"Translated\"].apply(preproc_spanish)\n",
    "\n",
    "eng_sentences = df[\"English\"].values\n",
    "spa_sentences = df[\"Translated\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = Tokenizer(filters=\"\")\n",
    "spa_tokenizer = Tokenizer(filters=\"\")\n",
    "eng_tokenizer.fit_on_texts(eng_sentences)\n",
    "spa_tokenizer.fit_on_texts(spa_sentences)\n",
    "\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "spa_vocab_size = len(spa_tokenizer.word_index) + 1\n",
    "\n",
    "eng_sequences = eng_tokenizer.texts_to_sequences(eng_sentences)\n",
    "spa_sequences = spa_tokenizer.texts_to_sequences(spa_sentences)\n",
    "\n",
    "max_eng_len = max(len(seq) for seq in eng_sequences)\n",
    "max_spa_len = max(len(seq) for seq in spa_sequences)\n",
    "\n",
    "eng_padded = pad_sequences(eng_sequences, maxlen=max_eng_len, padding=\"post\")\n",
    "spa_padded = pad_sequences(spa_sequences, maxlen=max_spa_len, padding=\"post\")\n",
    "\n",
    "# Convert to Torch tensors\n",
    "eng_tensor = torch.tensor(eng_padded, dtype=torch.long)\n",
    "spa_tensor = torch.tensor(spa_padded, dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(eng_tensor, spa_tensor[:, :-1], spa_tensor[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=160, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=160, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, (h, c) = self.lstm(x)\n",
    "        return output, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, query, values):\n",
    "        query = query.squeeze(0).unsqueeze(1)\n",
    "        score = self.V(torch.tanh(self.W1(query) + self.W2(values)))\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        context_vector = torch.sum(attention_weights * values, dim=1)\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.attention = BahdanauAttention(hidden_dim)\n",
    "\n",
    "    def forward(self, x, hidden, enc_output):\n",
    "        context_vector = self.attention(hidden[0], enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = torch.cat([context_vector.unsqueeze(1), x], dim=-1)\n",
    "        output, (h, c) = self.lstm(x, hidden)\n",
    "        return self.fc(output), (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        enc_output, h, c = self.encoder(inputs)\n",
    "        dec_hidden = (h, c)\n",
    "        dec_input = targets[:, 0].unsqueeze(1)\n",
    "        all_predictions = []\n",
    "\n",
    "        for t in range(targets.shape[1]):\n",
    "            predictions, dec_hidden = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            all_predictions.append(predictions)\n",
    "            dec_input = targets[:, t].unsqueeze(1)\n",
    "\n",
    "        return torch.cat(all_predictions, dim=1)\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        enc_output, h, c = self.encoder(inputs)\n",
    "        dec_hidden = (h, c)\n",
    "        dec_input = inputs[:, 0].unsqueeze(1)\n",
    "        all_predictions = []\n",
    "\n",
    "        for t in range(inputs.shape[1]):\n",
    "            predictions, dec_hidden = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            all_predictions.append(predictions)\n",
    "            dec_input = predictions.argmax(dim=2)\n",
    "\n",
    "        return torch.cat(all_predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "hidden_dim = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "encoder = Encoder(eng_vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "decoder = Decoder(spa_vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.5, patience=3, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion):\n",
    "    \"\"\"Evaluates the model on the validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "        for inputs, targets_in, targets_out in val_tqdm:\n",
    "            inputs, targets_in, targets_out = (\n",
    "                inputs.to(device),\n",
    "                targets_in.to(device),\n",
    "                targets_out.to(device),\n",
    "            )\n",
    "\n",
    "            outputs = model(inputs, targets_in)\n",
    "            loss = criterion(outputs.view(-1, spa_vocab_size), targets_out.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            val_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=50):\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    \"\"\"Trains the model with validation.\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "        for inputs, targets_in, targets_out in progress_bar:\n",
    "            inputs, targets_in, targets_out = (\n",
    "                inputs.to(device),\n",
    "                targets_in.to(device),\n",
    "                targets_out.to(device),\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, targets_in)\n",
    "\n",
    "            loss = criterion(outputs.view(-1, spa_vocab_size), targets_out.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            progress_bar.set_postfix(\n",
    "                loss=loss.item()\n",
    "            )\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        val_loss = validate(model, val_loader, criterion)\n",
    "        scheduler.step(val_loss)\n",
    "        writer.add_scalar(\"Loss/train\", avg_loss, epoch)\n",
    "        writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_loss:.4f} | Val Loss: {val_loss:.4f} | Learning Rate: {current_lr:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.6479\n",
      "Epoch 1/50 | Train Loss: 6.7451 | Val Loss: 6.6479 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.4017\n",
      "Epoch 2/50 | Train Loss: 6.4441 | Val Loss: 6.4017 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 6.1805\n",
      "Epoch 3/50 | Train Loss: 6.1731 | Val Loss: 6.1805 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.9825\n",
      "Epoch 4/50 | Train Loss: 5.9124 | Val Loss: 5.9825 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.8206\n",
      "Epoch 5/50 | Train Loss: 5.6850 | Val Loss: 5.8206 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.6776\n",
      "Epoch 6/50 | Train Loss: 5.4801 | Val Loss: 5.6776 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.5515\n",
      "Epoch 7/50 | Train Loss: 5.2913 | Val Loss: 5.5515 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.4374\n",
      "Epoch 8/50 | Train Loss: 5.1154 | Val Loss: 5.4374 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.3370\n",
      "Epoch 9/50 | Train Loss: 4.9509 | Val Loss: 5.3370 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.2423\n",
      "Epoch 10/50 | Train Loss: 4.7966 | Val Loss: 5.2423 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.1643\n",
      "Epoch 11/50 | Train Loss: 4.6518 | Val Loss: 5.1643 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.0867\n",
      "Epoch 12/50 | Train Loss: 4.5165 | Val Loss: 5.0867 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.0215\n",
      "Epoch 13/50 | Train Loss: 4.3881 | Val Loss: 5.0215 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.9635\n",
      "Epoch 14/50 | Train Loss: 4.2702 | Val Loss: 4.9635 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.9097\n",
      "Epoch 15/50 | Train Loss: 4.1558 | Val Loss: 4.9097 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.8579\n",
      "Epoch 16/50 | Train Loss: 4.0488 | Val Loss: 4.8579 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.8161\n",
      "Epoch 17/50 | Train Loss: 3.9501 | Val Loss: 4.8161 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.7714\n",
      "Epoch 18/50 | Train Loss: 3.8554 | Val Loss: 4.7714 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.7391\n",
      "Epoch 19/50 | Train Loss: 3.7666 | Val Loss: 4.7391 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.7089\n",
      "Epoch 20/50 | Train Loss: 3.6814 | Val Loss: 4.7089 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.6830\n",
      "Epoch 21/50 | Train Loss: 3.6030 | Val Loss: 4.6830 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.6581\n",
      "Epoch 22/50 | Train Loss: 3.5277 | Val Loss: 4.6581 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.6338\n",
      "Epoch 23/50 | Train Loss: 3.4570 | Val Loss: 4.6338 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.6095\n",
      "Epoch 24/50 | Train Loss: 3.3887 | Val Loss: 4.6095 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5992\n",
      "Epoch 25/50 | Train Loss: 3.3254 | Val Loss: 4.5992 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5819\n",
      "Epoch 26/50 | Train Loss: 3.2660 | Val Loss: 4.5819 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5622\n",
      "Epoch 27/50 | Train Loss: 3.2074 | Val Loss: 4.5622 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5622\n",
      "Epoch 28/50 | Train Loss: 3.1533 | Val Loss: 4.5622 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5435\n",
      "Epoch 29/50 | Train Loss: 3.1014 | Val Loss: 4.5435 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5328\n",
      "Epoch 30/50 | Train Loss: 3.0531 | Val Loss: 4.5328 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5244\n",
      "Epoch 31/50 | Train Loss: 3.0055 | Val Loss: 4.5244 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5201\n",
      "Epoch 32/50 | Train Loss: 2.9607 | Val Loss: 4.5201 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5145\n",
      "Epoch 33/50 | Train Loss: 2.9184 | Val Loss: 4.5145 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5102\n",
      "Epoch 34/50 | Train Loss: 2.8772 | Val Loss: 4.5102 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5074\n",
      "Epoch 35/50 | Train Loss: 2.8393 | Val Loss: 4.5074 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5008\n",
      "Epoch 36/50 | Train Loss: 2.8037 | Val Loss: 4.5008 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5009\n",
      "Epoch 37/50 | Train Loss: 2.7670 | Val Loss: 4.5009 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5050\n",
      "Epoch 38/50 | Train Loss: 2.7319 | Val Loss: 4.5050 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5035\n",
      "Epoch 39/50 | Train Loss: 2.6998 | Val Loss: 4.5035 | Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5048\n",
      "Epoch 40/50 | Train Loss: 2.6696 | Val Loss: 4.5048 | Learning Rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.4828\n",
      "Epoch 41/50 | Train Loss: 2.5835 | Val Loss: 4.4828 | Learning Rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.4890\n",
      "Epoch 42/50 | Train Loss: 2.5512 | Val Loss: 4.4890 | Learning Rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.4903\n",
      "Epoch 43/50 | Train Loss: 2.5312 | Val Loss: 4.4903 | Learning Rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.4970\n",
      "Epoch 44/50 | Train Loss: 2.5152 | Val Loss: 4.4970 | Learning Rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5037\n",
      "Epoch 45/50 | Train Loss: 2.4993 | Val Loss: 4.5037 | Learning Rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.4987\n",
      "Epoch 46/50 | Train Loss: 2.4542 | Val Loss: 4.4987 | Learning Rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5037\n",
      "Epoch 47/50 | Train Loss: 2.4381 | Val Loss: 4.5037 | Learning Rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5045\n",
      "Epoch 48/50 | Train Loss: 2.4285 | Val Loss: 4.5045 | Learning Rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5086\n",
      "Epoch 49/50 | Train Loss: 2.4200 | Val Loss: 4.5086 | Learning Rate: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.5097\n",
      "Epoch 50/50 | Train Loss: 2.3960 | Val Loss: 4.5097 | Learning Rate: 0.000125\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=50)\n",
    "\n",
    "torch.save(model.state_dict(), \"seq2seq-wortok.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 256\n",
    "hidden_dim = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = Encoder(eng_vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "decoder = Decoder(spa_vocab_size, embedding_dim, hidden_dim).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\"seq2seq-wortok.pth\", weights_only=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 47])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "a, b, c = next(iter(val_loader))\n",
    "a = a.to(device)\n",
    "b = b.to(device)\n",
    "c = c.to(device)\n",
    "with torch.no_grad():\n",
    "    x = model.predict(a)\n",
    "x = x.argmax(dim=2)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.cpu().numpy()\n",
    "b = b.cpu().numpy()\n",
    "a = a.cpu().numpy()\n",
    "preds = []\n",
    "targets = []\n",
    "original = []\n",
    "for i in range(x.shape[0]):\n",
    "    preds.append(spa_tokenizer.sequences_to_texts([x[i]])[0])\n",
    "    targets.append([spa_tokenizer.sequences_to_texts([b[i]])[0]])\n",
    "    original.append([eng_tokenizer.sequences_to_texts([a[i]])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[good to see you tom]</td>\n",
       "      <td>si me ver tom tom tom tom a a a a a a a a a a ...</td>\n",
       "      <td>[qué bueno verte tom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i thought tom would get here ahead of us]</td>\n",
       "      <td>nos que me aquí de nosotros nosotros nosotros ...</td>\n",
       "      <td>[pensé que tom llegaría aquí antes que nosotros]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[he asked his friends for help]</td>\n",
       "      <td>la que a ayuda ayuda sus a ayuda su ayuda la a...</td>\n",
       "      <td>[él le pidió ayuda a sus amigos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tom was a tank commander]</td>\n",
       "      <td>fue un de con guerra abril guerra trigo guerra...</td>\n",
       "      <td>[tom fue un comandante de tanques]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[she doesnt understand you]</td>\n",
       "      <td>no te lo tú lo tú lo ti usted entiende verdad ...</td>\n",
       "      <td>[ella no les entiende]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[this box is not as big as that one]</td>\n",
       "      <td>caja no tan como grande mi es grande mi es que...</td>\n",
       "      <td>[esta caja no es tan grande como esa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[we should go]</td>\n",
       "      <td>ir ir ir ayudar ir caza ladrillo grafitis trig...</td>\n",
       "      <td>[deberíamos irnos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[thats not my wife]</td>\n",
       "      <td>que es mi esposa mi padre mi padre su idea a p...</td>\n",
       "      <td>[esa no es mi esposa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[who taught you that]</td>\n",
       "      <td>se que eso eso eso eso eso eso eso eso eso eso...</td>\n",
       "      <td>[quién te ha enseñado eso]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[tom says he doesnt think its possible to do t...</td>\n",
       "      <td>dice que no que eso hacer hacer hacer hacerlo ...</td>\n",
       "      <td>[tom dice que no cree que sea posible hacer eso]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Original  \\\n",
       "0                              [good to see you tom]   \n",
       "1         [i thought tom would get here ahead of us]   \n",
       "2                    [he asked his friends for help]   \n",
       "3                         [tom was a tank commander]   \n",
       "4                        [she doesnt understand you]   \n",
       "5               [this box is not as big as that one]   \n",
       "6                                     [we should go]   \n",
       "7                                [thats not my wife]   \n",
       "8                              [who taught you that]   \n",
       "9  [tom says he doesnt think its possible to do t...   \n",
       "\n",
       "                                          Prediction  \\\n",
       "0  si me ver tom tom tom tom a a a a a a a a a a ...   \n",
       "1  nos que me aquí de nosotros nosotros nosotros ...   \n",
       "2  la que a ayuda ayuda sus a ayuda su ayuda la a...   \n",
       "3  fue un de con guerra abril guerra trigo guerra...   \n",
       "4  no te lo tú lo tú lo ti usted entiende verdad ...   \n",
       "5  caja no tan como grande mi es grande mi es que...   \n",
       "6  ir ir ir ayudar ir caza ladrillo grafitis trig...   \n",
       "7  que es mi esposa mi padre mi padre su idea a p...   \n",
       "8  se que eso eso eso eso eso eso eso eso eso eso...   \n",
       "9  dice que no que eso hacer hacer hacer hacerlo ...   \n",
       "\n",
       "                                             Target  \n",
       "0                             [qué bueno verte tom]  \n",
       "1  [pensé que tom llegaría aquí antes que nosotros]  \n",
       "2                  [él le pidió ayuda a sus amigos]  \n",
       "3                [tom fue un comandante de tanques]  \n",
       "4                            [ella no les entiende]  \n",
       "5             [esta caja no es tan grande como esa]  \n",
       "6                                [deberíamos irnos]  \n",
       "7                             [esa no es mi esposa]  \n",
       "8                        [quién te ha enseñado eso]  \n",
       "9  [tom dice que no cree que sea posible hacer eso]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"Original\": original[:10], \"Prediction\": preds[:10], \"Target\": targets[:10]}\n",
    ")\n",
    "df.to_csv(\"attention-wordlevel.csv\", index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 2.264164155209104\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "\n",
    "def calculate_bleu_score(preds, targets):\n",
    "    bleu = sacrebleu.corpus_bleu(preds, targets, force=True)  \n",
    "    return bleu.score\n",
    "\n",
    "bleu_score = calculate_bleu_score(preds, targets)\n",
    "print(f\"BLEU Score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.409396884773723,\n",
       "  'p': 0.19576793228415262,\n",
       "  'f': 0.2399486631711552},\n",
       " 'rouge-2': {'r': 0.06920765866078366,\n",
       "  'p': 0.021683212182092855,\n",
       "  'f': 0.029892009074832405},\n",
       " 'rouge-l': {'r': 0.37724361626935154,\n",
       "  'p': 0.1793810192524139,\n",
       "  'f': 0.22004146595394855}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rouge\n",
    "\n",
    "rouge = rouge.Rouge()\n",
    "flat_targets = [t[0] for t in targets]  \n",
    "scores = rouge.get_scores(preds, flat_targets, avg=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690.0191938579654"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ter(preds, targets):\n",
    "    return sacrebleu.corpus_ter(preds, [targets]).score\n",
    "\n",
    "\n",
    "ter(preds, flat_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
