{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj5quK5PsRbl",
        "outputId": "7a8ca79d-5094-4b25-e84a-3d92de9cb277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shusrith/imbd-dataset-tokenized?dataset_version_number=7...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31.3M/31.3M [00:03<00:00, 10.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/shusrith/imbd-dataset-tokenized/versions/7\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shusrith/imbd-dataset-tokenized\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "le5wOLd3sbza",
        "outputId": "66b9039e-5c19-44dd-ce40-d5e261cc6097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review  sentiment\n",
              "0      [27, 4, 1, 75, 1944, 44, 1062, 11, 100, 143, 3...          1\n",
              "1      [119, 203, 3258, 68, 13, 36, 1581, 8, 12, 2198...          1\n",
              "2      [3, 384, 116, 356, 1, 1338, 2937, 6, 51, 17935...          1\n",
              "3      [9, 192, 10, 12, 3, 384, 94, 5, 1120, 57, 19, ...          1\n",
              "4      [667, 214, 3, 233, 113, 3, 116, 435, 3556, 120...          0\n",
              "...                                                  ...        ...\n",
              "79534  [9, 227, 3, 3510, 4325, 7, 0, 8342, 4602, 31, ...          0\n",
              "79535  [126, 109, 4, 82, 1, 1587, 4, 6509, 2263, 8903...          0\n",
              "79536  [140, 161, 5, 24, 5, 2964, 14, 1, 899, 912, 2,...          0\n",
              "79537  [700, 423, 2193, 17142, 1, 0, 11, 12204, 4212,...          0\n",
              "79538  [54, 27, 5810, 1, 340, 2145, 91, 5, 25, 318, 5...          0\n",
              "\n",
              "[79539 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e665ef2b-0af5-4a0c-97ae-579555ee6c68\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[27, 4, 1, 75, 1944, 44, 1062, 11, 100, 143, 3...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[119, 203, 3258, 68, 13, 36, 1581, 8, 12, 2198...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[3, 384, 116, 356, 1, 1338, 2937, 6, 51, 17935...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[9, 192, 10, 12, 3, 384, 94, 5, 1120, 57, 19, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[667, 214, 3, 233, 113, 3, 116, 435, 3556, 120...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79534</th>\n",
              "      <td>[9, 227, 3, 3510, 4325, 7, 0, 8342, 4602, 31, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79535</th>\n",
              "      <td>[126, 109, 4, 82, 1, 1587, 4, 6509, 2263, 8903...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79536</th>\n",
              "      <td>[140, 161, 5, 24, 5, 2964, 14, 1, 899, 912, 2,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79537</th>\n",
              "      <td>[700, 423, 2193, 17142, 1, 0, 11, 12204, 4212,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79538</th>\n",
              "      <td>[54, 27, 5810, 1, 340, 2145, 91, 5, 25, 318, 5...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>79539 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e665ef2b-0af5-4a0c-97ae-579555ee6c68')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e665ef2b-0af5-4a0c-97ae-579555ee6c68 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e665ef2b-0af5-4a0c-97ae-579555ee6c68');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02752605-f155-475b-afa9-99ee0121ac2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02752605-f155-475b-afa9-99ee0121ac2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02752605-f155-475b-afa9-99ee0121ac2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_07cfc0c3-de2e-48c3-b98e-d6b82b2b7d71\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_07cfc0c3-de2e-48c3-b98e-d6b82b2b7d71 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 79539,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 78856,\n        \"samples\": [\n          \"[1035, 29, 30, 2, 1, 4443, 34, 14688, 0, 5, 3232, 851, 0, 37, 3439, 66, 3037, 5437, 2, 30, 4, 3, 2199, 447, 3, 216, 164, 394, 11, 276, 97, 79, 17, 1, 64, 404, 19, 2, 2588, 19, 1, 4595, 621, 197, 3439, 11847, 54, 1, 328, 65, 20, 583, 51, 72, 29, 30, 2, 11, 276, 2652, 3, 10423, 5, 10, 16, 83, 37, 9, 295, 10, 2588, 1382, 39, 19, 3439, 11847, 66, 46, 73, 50, 57, 66, 1, 64, 73, 50, 41, 19781, 426, 118, 90, 270, 1, 328, 0, 73, 46, 50, 17, 33, 1144, 36, 71, 184, 5, 63, 1, 1140, 4, 6597, 8940, 849, 17434, 2, 4319, 2391, 51, 3145, 296, 1380, 11, 12, 27, 145, 41, 10, 64, 11, 9, 192, 12, 61, 590, 23, 1265, 2, 2327, 7, 19781, 118, 61, 3319, 2, 28, 97, 77, 11, 276, 4178, 50, 443, 69, 47, 12, 4178, 12, 221, 69, 15, 1, 86, 169, 1192, 9, 88, 101, 536, 119, 102, 10, 170, 2, 9, 88, 101, 10, 0, 25, 11, 867, 15, 288, 35, 10578, 9, 109, 3439, 17, 201, 32, 4012, 6876, 2042, 317, 10, 139, 25, 32, 215, 102]\",\n          \"[23, 118, 1, 720, 176, 1707, 10894, 1974, 13187, 595, 15144, 791, 2586, 3306, 3934, 2227, 2193, 1770, 18685, 1840, 0, 1833, 18685, 10690, 6552, 839, 7004, 0, 1894, 444, 0, 4185, 2577, 7846, 589, 0, 0, 2, 589, 0, 1399, 1, 511, 5705, 42, 157, 320, 1051, 18523, 2383, 6, 3, 3384, 11, 263, 5, 117, 11, 254, 3, 48, 171, 3, 16015, 309, 176, 2, 3, 224, 11, 6, 3, 13287, 0, 120, 20, 2652, 0, 3, 984, 2418, 1640, 1034, 4, 0, 302, 2383, 2, 9767, 15472, 24, 2525, 585, 1, 1282, 123, 4, 3, 106, 37, 3321, 3921, 655, 17, 46, 6, 125, 3, 12358, 9344, 7, 10, 836, 64, 4, 1, 621, 197, 3321, 23, 425, 2, 23, 1394, 11, 76, 1374, 2137, 11350, 1194, 2, 3703, 17, 1051, 8937, 6, 1998, 5, 2977, 11, 275, 4, 6323, 11, 0, 1111, 14, 10, 18, 42, 119, 46, 12, 3, 16, 92, 11, 139, 24, 73, 0, 8451, 10, 6, 8, 122, 125, 66, 8, 108, 73, 1480, 9, 1079, 10, 27, 3547, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001]\",\n          \"[24, 39, 104, 10, 18, 15, 1, 87, 57, 100, 11024, 8, 19, 265, 8, 261, 597, 13, 3, 685, 579, 5, 2171, 7, 19, 1, 105, 5366, 91, 474, 10, 18, 149, 951, 5, 24, 1, 162, 389, 13, 1, 5366, 93, 2, 2867, 45, 4, 1, 709, 2, 287, 690, 13, 3163, 2, 45, 132, 299, 15906, 7996, 6, 570, 5, 160, 29, 17, 474, 58, 399, 491, 42, 3, 1036, 12, 264, 5, 40, 413, 0, 720, 212, 569, 37, 8, 12, 221, 13, 3, 1954, 5, 171, 11250, 35, 80, 522, 5366, 1, 0, 270, 9906, 276, 6104, 11, 26, 56, 137, 19, 5, 15618, 93, 37, 3477, 913, 2121, 0, 523, 45, 4, 1, 647, 0, 4, 1, 0, 403, 7, 1, 18, 569, 37, 33, 65, 2782, 5, 5167, 62, 8762, 2, 1, 278, 19, 62, 1417, 4347, 33, 65, 254, 79, 241, 250, 10, 18, 9, 399, 25, 36, 0, 42, 9, 12, 1002, 15, 52, 118, 30, 10, 1149, 10, 18, 2511, 51, 116, 8678, 5, 102, 2, 12, 2567, 418, 194, 104, 3, 163, 416, 105, 407, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001, 20001]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/root/.cache/kagglehub/datasets/shusrith/imbd-dataset-tokenized/versions/7/data.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFXGGTWmtAqK",
        "outputId": "07940334-0426-4bcf-a7e6-534508ddbedd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import ast\n",
        "df[\"review\"] = df[\"review\"].apply(lambda x: ast.literal_eval(x))\n",
        "type(df.iloc[0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "logoQ45stnsJ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=20001)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        if h is None:\n",
        "            h = torch.zeros(1, x.size(0), self.hidden_dim).to(\"cuda\")\n",
        "        x, h = self.rnn(x, h)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x, h.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2a9HcAsZG93t"
      },
      "outputs": [],
      "source": [
        "model = RNNModel(64, 128, 20001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=20001)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        if h is None:\n",
        "            h = (\n",
        "                torch.zeros(1, x.size(0), self.hidden_dim).to(\"cuda\"),\n",
        "                torch.zeros(1, x.size(0), self.hidden_dim).to(\"cuda\"),\n",
        "            )\n",
        "        x, h = self.lstm(x, h)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x, (h[0].detach(), h[1].detach())\n",
        "\n",
        "model = LSTMModel(64, 128, 20002)"
      ],
      "metadata": {
        "id": "MFeb1M0QxHWY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=20001)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embedding(x)\n",
        "        if h is None:\n",
        "            h = torch.zeros(1, x.size(0), self.hidden_dim).to(\"cuda\")\n",
        "        x, h = self.gru(x, h)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x, h.detach()\n",
        "\n",
        "model = GRUModel(64, 128, 20002)"
      ],
      "metadata": {
        "id": "q7-USplhzMXQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=20001)\n",
        "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embedding(x)\n",
        "        if h is None:\n",
        "            h = (\n",
        "                torch.zeros(2, x.size(0), self.bilstm.hidden_size).to(\"cuda\"),\n",
        "                torch.zeros(2, x.size(0), self.bilstm.hidden_size).to(\"cuda\"),\n",
        "            )\n",
        "        x, h = self.bilstm(x, h)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x, h[0].detach()\n",
        "\n",
        "model = BiLSTMModel(64, 128, 20002)"
      ],
      "metadata": {
        "id": "0Cjti93kz_Qb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class StackedLSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_layers):\n",
        "        super(StackedLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=20001)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embedding(x)\n",
        "        if h is None:\n",
        "            h = (\n",
        "                torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(\"cuda\"),\n",
        "                torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(\"cuda\"),\n",
        "            )\n",
        "        x, h = self.lstm(x, h)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x, (h[0].detach(), h[1].detach())\n",
        "\n",
        "model = StackedLSTMModel(64, 128, 20002, 2)"
      ],
      "metadata": {
        "id": "f7Pk3xFs1Sza"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class StackedBiLSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim1, hidden_dim2, vocab_size):\n",
        "        super(StackedBiLSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=20001)\n",
        "\n",
        "        # First BiLSTM Layer\n",
        "        self.bilstm1 = nn.LSTM(embedding_dim, hidden_dim1, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Second BiLSTM Layer (takes hidden_dim1 * 2 as input due to bidirectionality)\n",
        "        self.bilstm2 = nn.LSTM(hidden_dim1 * 2, hidden_dim2, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim2 * 2, 1)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # Initialize hidden states if not provided\n",
        "        if h is None:\n",
        "            h1 = (\n",
        "                torch.zeros(2, x.size(0), self.bilstm1.hidden_size, device=x.device),\n",
        "                torch.zeros(2, x.size(0), self.bilstm1.hidden_size, device=x.device),\n",
        "            )\n",
        "        else:\n",
        "            h1 = h[:2]  # Extract first BiLSTM's hidden and cell states\n",
        "\n",
        "        # First BiLSTM Layer\n",
        "        x, h1 = self.bilstm1(x, h1)\n",
        "\n",
        "        # Initialize hidden states for second LSTM\n",
        "        if h is None:\n",
        "            h2 = (\n",
        "                torch.zeros(2, x.size(0), self.bilstm2.hidden_size, device=x.device),\n",
        "                torch.zeros(2, x.size(0), self.bilstm2.hidden_size, device=x.device),\n",
        "            )\n",
        "        else:\n",
        "            h2 = h[2:]  # Extract second BiLSTM's hidden and cell states\n",
        "\n",
        "        # Second BiLSTM Layer\n",
        "        x, h2 = self.bilstm2(x, h2)\n",
        "\n",
        "        # Take the last timestep output\n",
        "        x = x[:, -1, :]\n",
        "\n",
        "        # Fully connected layer\n",
        "        x = self.fc(x)\n",
        "\n",
        "        # Return output and hidden states\n",
        "        return x, (h1[0].detach(), h1[1].detach(), h2[0].detach(), h2[1].detach())\n",
        "\n",
        "# Define model with first layer (128 units) and second layer (64 units)\n",
        "model = StackedBiLSTMModel(embedding_dim=64, hidden_dim1=128, hidden_dim2=64, vocab_size=20002)\n",
        "model = model.to(\"cuda\")  # Move model to GPU\n"
      ],
      "metadata": {
        "id": "Xx6kp3Ke2h4r"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "qy6dBhC6HHUi"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "batch_size = 256\n",
        "seq_len = 200\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "N4zMgtmMIQ82"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "train = TensorDataset(\n",
        "    torch.tensor(df[\"review\"][:40000].tolist(), dtype=torch.long),\n",
        "    torch.tensor(df[\"sentiment\"][:40000].tolist(), dtype=torch.float32),\n",
        ")\n",
        "test = TensorDataset(\n",
        "    torch.tensor(df[\"review\"][40000:].tolist(), dtype=torch.long),\n",
        "    torch.tensor(df[\"sentiment\"][40000:].tolist(), dtype=torch.float32),\n",
        ")\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "RZECYzBCIntY"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20002\n",
        "hidden_dim = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# for rnn, lstm, gru"
      ],
      "metadata": {
        "id": "nPFyj1rs0TRC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kVLXhPGHSEr",
        "outputId": "65346d74-7d22-4b78-f564-05221146368f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 17.03it/s, loss=0.691]\n",
            "Epoch 1/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 43.82it/s, loss=0.679]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.6899 | Train Acc: 0.5208 | Val Loss: 0.6744 | Val Acc: 0.5633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 16.55it/s, loss=0.688]\n",
            "Epoch 2/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 42.90it/s, loss=0.725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 | Train Loss: 0.6881 | Train Acc: 0.5381 | Val Loss: 0.6908 | Val Acc: 0.5176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 157/157 [00:10<00:00, 15.24it/s, loss=0.692]\n",
            "Epoch 3/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 42.93it/s, loss=0.702]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 | Train Loss: 0.6909 | Train Acc: 0.5164 | Val Loss: 0.6901 | Val Acc: 0.5117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 16.97it/s, loss=0.665]\n",
            "Epoch 4/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 44.38it/s, loss=0.725]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 | Train Loss: 0.6859 | Train Acc: 0.5388 | Val Loss: 0.6735 | Val Acc: 0.5862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 17.12it/s, loss=0.646]\n",
            "Epoch 5/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 44.46it/s, loss=0.571]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 | Train Loss: 0.6737 | Train Acc: 0.5625 | Val Loss: 0.6258 | Val Acc: 0.6772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 17.22it/s, loss=0.42]\n",
            "Epoch 6/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 44.31it/s, loss=0.423]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 | Train Loss: 0.4888 | Train Acc: 0.7657 | Val Loss: 0.4400 | Val Acc: 0.7947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 16.07it/s, loss=0.341]\n",
            "Epoch 7/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 43.81it/s, loss=0.382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 | Train Loss: 0.3604 | Train Acc: 0.8448 | Val Loss: 0.4074 | Val Acc: 0.8141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 16.86it/s, loss=0.292]\n",
            "Epoch 8/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 43.73it/s, loss=0.431]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 | Train Loss: 0.2952 | Train Acc: 0.8790 | Val Loss: 0.3971 | Val Acc: 0.8278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 16.56it/s, loss=0.261]\n",
            "Epoch 9/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 43.99it/s, loss=0.441]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 | Train Loss: 0.2489 | Train Acc: 0.9019 | Val Loss: 0.3932 | Val Acc: 0.8321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10 [Train]: 100%|██████████| 157/157 [00:09<00:00, 16.81it/s, loss=0.419]\n",
            "Epoch 10/10 [Val]: 100%|██████████| 155/155 [00:03<00:00, 43.47it/s, loss=0.535]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 | Train Loss: 0.2117 | Train Acc: 0.9197 | Val Loss: 0.4290 | Val Acc: 0.8312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "model = model.to(\"cuda\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
        "\n",
        "    total_train_loss = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for train_data, train_labels in train_tqdm:\n",
        "        train_data, train_labels = train_data.to(\"cuda\"), train_labels.to(\"cuda\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = model(train_data)\n",
        "        output = output.squeeze()\n",
        "\n",
        "        loss = criterion(output, train_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        predictions = (torch.sigmoid(output) > 0.5).float()\n",
        "        correct_train += (predictions == train_labels).sum().item()\n",
        "        total_train += train_labels.size(0)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        train_tqdm.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    train_acc = correct_train / total_train\n",
        "\n",
        "    # ------------------- Validation Loop -------------------\n",
        "    model.eval()\n",
        "    val_tqdm = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\")\n",
        "\n",
        "    total_val_loss = 0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_data, val_labels in val_tqdm:\n",
        "            val_data, val_labels = val_data.to(\"cuda\"), val_labels.to(\"cuda\")\n",
        "\n",
        "            output, _ = model(val_data)\n",
        "            output = output.squeeze()\n",
        "\n",
        "            loss = criterion(output, val_labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            predictions = (torch.sigmoid(output) > 0.5).float()\n",
        "            correct_val += (predictions == val_labels).sum().item()\n",
        "            total_val += val_labels.size(0)\n",
        "\n",
        "            val_tqdm.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(test_loader)\n",
        "    val_acc = correct_val / total_val\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\"\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}