{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":280122,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239973,"modelId":261627}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"_uuid":"68bcf541-db2e-40cf-8618-925785d40bf4","_cell_guid":"ec285165-22a6-43c0-9c3c-a6e0220a51e5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-09T12:39:20.436301Z","iopub.execute_input":"2025-03-09T12:39:20.436601Z","iopub.status.idle":"2025-03-09T12:39:27.883895Z","shell.execute_reply.started":"2025-03-09T12:39:20.436571Z","shell.execute_reply":"2025-03-09T12:39:27.883005Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Define transformations (normalize to match pre-trained settings)\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n\ntestset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)","metadata":{"_uuid":"7c4e5891-24b8-440a-a4a5-ba6d7abbecee","_cell_guid":"2d82c844-acb2-40cd-94b0-5435a62c125f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T12:39:31.197462Z","iopub.execute_input":"2025-03-09T12:39:31.197791Z","iopub.status.idle":"2025-03-09T12:39:38.159998Z","shell.execute_reply.started":"2025-03-09T12:39:31.197760Z","shell.execute_reply":"2025-03-09T12:39:38.159063Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170M/170M [00:03<00:00, 49.8MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            bias=False,\n        )\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(\n            out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(\n                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n                ),\n                nn.BatchNorm2d(out_channels),\n            )\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)  \n        return torch.relu(out)\n\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n\n        self.layer1 = ResidualBlock(64, 128, stride=2)\n        self.layer2 = ResidualBlock(128, 256, stride=2)\n        self.layer3 = ResidualBlock(256, 512, stride=2)\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = torch.relu(self.bn1(self.conv1(x)))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avg_pool(x)\n        x = torch.flatten(x, 1)\n        return self.fc(x)","metadata":{"_uuid":"023c9a35-5d25-4404-a498-ca27b897ab70","_cell_guid":"c386c74e-a27f-40d9-82d3-9aa886a1baab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T12:39:38.161200Z","iopub.execute_input":"2025-03-09T12:39:38.161419Z","iopub.status.idle":"2025-03-09T12:39:38.171658Z","shell.execute_reply.started":"2025-03-09T12:39:38.161401Z","shell.execute_reply":"2025-03-09T12:39:38.170791Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def fgsm_attack(model, images, labels, epsilon=0.1):\n    images = images.clone().detach().to(\"cuda\").requires_grad_(True)\n    labels = labels.to(\"cuda\")\n\n    output = model(images)\n    loss = nn.CrossEntropyLoss()(output, labels)\n\n    model.zero_grad()\n    loss.backward()\n\n    adv_images = images + epsilon * images.grad.sign()\n    adv_images = torch.clamp(adv_images, 0, 1)  # Keep pixel values in valid range\n    return adv_images.detach()","metadata":{"_uuid":"39d95eac-d972-499e-9b33-ebbdb32e7a59","_cell_guid":"c6bd48eb-e454-438b-aa08-acf45f6783ba","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:45:56.194211Z","iopub.execute_input":"2025-03-08T09:45:56.194560Z","iopub.status.idle":"2025-03-08T09:45:56.199628Z","shell.execute_reply.started":"2025-03-08T09:45:56.194529Z","shell.execute_reply":"2025-03-08T09:45:56.198737Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = CNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\nnum_epochs = 30\nepsilon = 0.1  # FGSM perturbation strength\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        # Generate adversarial examples\n        adv_images = fgsm_attack(model, images, labels, epsilon=epsilon)\n\n        # Forward pass on clean and adversarial images\n        optimizer.zero_grad()\n        clean_outputs = model(images)\n        adv_outputs = model(adv_images)\n\n        loss_clean = criterion(clean_outputs, labels)\n        loss_adv = criterion(adv_outputs, labels)\n        alpha = max(0.5, 1-epoch/num_epochs)\n        loss = alpha * loss_clean + (1-alpha)*loss_adv\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n\n# Save the adversarially trained model\ntorch.save(model.state_dict(), \"/kaggle/working/cifar10_adv_train.pth\")","metadata":{"_uuid":"777b100b-16fa-48c6-8d6f-b478ff884d90","_cell_guid":"8aeca590-0c8e-4c15-a3a5-e9417d466d79","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:47:01.351253Z","iopub.execute_input":"2025-03-08T09:47:01.351629Z","iopub.status.idle":"2025-03-08T09:57:30.386713Z","shell.execute_reply.started":"2025-03-08T09:47:01.351597Z","shell.execute_reply":"2025-03-08T09:57:30.385875Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = CNN().to(\"cuda\")\nmodel.load_state_dict(torch.load(\"/kaggle/input/siddhi-is-dumb-as-hell/pytorch/default/1/cifar10_adv_train.pth\", weights_only=True))","metadata":{"_uuid":"ceaecf3c-8e61-48f4-9664-2b037b08e104","_cell_guid":"221fa066-28e4-4975-b4e4-c2e53580619e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-09T12:41:10.218268Z","iopub.execute_input":"2025-03-09T12:41:10.218588Z","iopub.status.idle":"2025-03-09T12:41:10.975136Z","shell.execute_reply.started":"2025-03-09T12:41:10.218564Z","shell.execute_reply":"2025-03-09T12:41:10.974400Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import random\n\ntarget_class = torch.tensor([9], dtype=torch.long, device=\"cuda\")\nmodel = model.to(\"cuda\")\nmodel.eval()\nc = 0\nl = 0\nfor i in range(100):\n    j = random.randint(1, len(trainset))\n    input_image = trainset[j][0].unsqueeze(0).to(\"cuda\")\n    input_image = input_image.detach().clone()\n    input_image.requires_grad_(True)\n    output = model(input_image)\n    loss = -torch.nn.functional.cross_entropy(output, target_class)\n\n    model.zero_grad()\n    loss.backward()\n\n    with torch.no_grad():\n        input_image += 0.1 * input_image.grad.sign()\n        input_image.clamp_(0, 1)\n    input_image.grad.zero_()\n    a = model(input_image)\n    pred = torch.argmax(torch.nn.functional.softmax(a, dim=1)).item()\n    if pred == trainset[j][1]:\n        c += 1\n    l += loss.item()\nprint(c / 100)\nprint(\"average loss\", l / 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T12:42:59.401392Z","iopub.execute_input":"2025-03-09T12:42:59.401681Z","iopub.status.idle":"2025-03-09T12:42:59.960657Z","shell.execute_reply.started":"2025-03-09T12:42:59.401657Z","shell.execute_reply":"2025-03-09T12:42:59.959905Z"}},"outputs":[{"name":"stdout","text":"0.7\naverage loss -14.80088784060597\n","output_type":"stream"}],"execution_count":35}]}