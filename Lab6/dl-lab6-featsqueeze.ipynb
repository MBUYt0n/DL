{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\ndef feature_squeeze(x, bit_depth=5):\n    \"\"\"Reduce the bit-depth of the input image.\"\"\"\n    max_val = torch.tensor(2**bit_depth - 1).to(x.device)\n    x = torch.round(x * max_val) / max_val \n    return x\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        return F.relu(out)\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n\n        self.layer1 = ResidualBlock(64, 128, stride=2)\n        self.layer2 = ResidualBlock(128, 256, stride=2)\n        self.layer3 = ResidualBlock(256, 512, stride=2)\n\n        self.dropout = nn.Dropout(0.3)\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = feature_squeeze(x)  # Apply feature squeezing before passing through the model\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avg_pool(x)\n        x = torch.flatten(x, 1)\n        x = self.dropout(x)\n        return self.fc(x)","metadata":{"_uuid":"a86e761b-5a59-48ca-a98c-730bcea0edd0","_cell_guid":"9cda1311-b450-481d-9fc9-e4036691d97c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T10:45:24.944371Z","iopub.execute_input":"2025-03-09T10:45:24.944706Z","iopub.status.idle":"2025-03-09T10:45:24.955169Z","shell.execute_reply.started":"2025-03-09T10:45:24.944678Z","shell.execute_reply":"2025-03-09T10:45:24.954221Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"import torchvision.transforms as transforms\nimport numpy as np\nimport cv2\n\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n])","metadata":{"_uuid":"fe71ade0-e06d-46f5-a9f3-1d89c542319c","_cell_guid":"863abdf2-ddae-4362-a521-6244fe583d32","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T10:45:26.766500Z","iopub.execute_input":"2025-03-09T10:45:26.766870Z","iopub.status.idle":"2025-03-09T10:45:26.771991Z","shell.execute_reply.started":"2025-03-09T10:45:26.766837Z","shell.execute_reply":"2025-03-09T10:45:26.771220Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"import torch\nimport torchvision\ntrain = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform_train)\ntest = torchvision.datasets.CIFAR10(root='./data',train=False,download=False,transform=transform_test)\ntrainloader = torch.utils.data.DataLoader(train,batch_size=128,shuffle=True)\ntestloader = torch.utils.data.DataLoader(test,batch_size=128,shuffle=False)","metadata":{"_uuid":"20dedd39-ef12-40ec-b843-b3a8434cc070","_cell_guid":"be80f2b8-10d6-4942-9540-7416cb81b052","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T10:45:26.985612Z","iopub.execute_input":"2025-03-09T10:45:26.985948Z","iopub.status.idle":"2025-03-09T10:45:28.354915Z","shell.execute_reply.started":"2025-03-09T10:45:26.985920Z","shell.execute_reply":"2025-03-09T10:45:28.354206Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"model = CNN()","metadata":{"_uuid":"458d443b-9db4-4476-8d40-230fdbf1cf38","_cell_guid":"a7826ab5-9bd3-4a28-983b-17a2ef55364b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T10:45:44.347376Z","iopub.execute_input":"2025-03-09T10:45:44.347672Z","iopub.status.idle":"2025-03-09T10:45:44.387152Z","shell.execute_reply.started":"2025-03-09T10:45:44.347649Z","shell.execute_reply":"2025-03-09T10:45:44.386259Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\n\ndevice = \"cuda\"\nloss = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\nmodel = model.to(device)\nfrom tqdm import tqdm\n\nlr = 0.001\nfor i in range(20):\n    correct, total, running_loss = 0, 0, 0\n    train_bar = tqdm(trainloader, desc=f'Train Epoch {i}')\n\n    for image, label in train_bar:\n        image, label = image.to(device), label.to(device)\n\n        out = model(image)\n        loss_value = loss(out, label)\n\n        optimizer.zero_grad()\n        loss_value.backward()\n        optimizer.step()\n\n        predictions = out.argmax(dim=1)\n        correct += (predictions == label).sum().item()\n        total += label.size(0)\n        running_loss += loss_value.item()\n\n        train_bar.set_postfix(loss=running_loss / total, acc=100 * correct / total)\n        writer.add_scalar('Loss/train', running_loss / total, i)    \n        writer.add_scalar('Accuracy/train', 100 * correct / total, i)\n    correct, total, test_loss = 0, 0, 0\n    test_bar = tqdm(testloader, desc=f'Test Epoch {i}')\n\n    with torch.no_grad():\n        for test, test_label in test_bar:\n            test, test_label = test.to(device), test_label.to(device)\n\n            test_out = model(test)\n            loss_value = loss(test_out, test_label)\n            test_loss += loss_value.item()\n\n            predictions = test_out.argmax(dim=1)\n            correct += (predictions == test_label).sum().item()\n            total += test_label.size(0)\n\n            test_bar.set_postfix(loss=test_loss / total, acc=100 * correct / total)\n            writer.add_scalar('Loss/test', test_loss / total, i)\n            writer.add_scalar('Accuracy/test', 100 * correct / total, i)\n    scheduler.step(test_loss)\n    if optimizer.param_groups[0][\"lr\"] != lr:\n        lr = optimizer.param_groups[0][\"lr\"]\n        print(f\"Updated learning rate: {lr}\")","metadata":{"_uuid":"332d7b44-ce88-433f-baef-30e2ef343e45","_cell_guid":"380d85bc-4bfa-485c-949c-efd52ce2bba4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-09T10:45:45.921043Z","iopub.execute_input":"2025-03-09T10:45:45.921339Z"}},"outputs":[{"name":"stderr","text":"Train Epoch 0: 100%|██████████| 391/391 [00:38<00:00, 10.27it/s, acc=49.6, loss=0.0108]\nTest Epoch 0: 100%|██████████| 79/79 [00:03<00:00, 22.08it/s, acc=58.2, loss=0.00907]\nTrain Epoch 1: 100%|██████████| 391/391 [00:37<00:00, 10.41it/s, acc=64.7, loss=0.00774]\nTest Epoch 1: 100%|██████████| 79/79 [00:03<00:00, 21.59it/s, acc=66.2, loss=0.00753]\nTrain Epoch 2: 100%|██████████| 391/391 [00:37<00:00, 10.45it/s, acc=71.4, loss=0.00632]\nTest Epoch 2: 100%|██████████| 79/79 [00:03<00:00, 21.88it/s, acc=72.7, loss=0.00618]\nTrain Epoch 3: 100%|██████████| 391/391 [00:38<00:00, 10.21it/s, acc=75.8, loss=0.00541]\nTest Epoch 3: 100%|██████████| 79/79 [00:03<00:00, 21.87it/s, acc=77, loss=0.00545]  \nTrain Epoch 4: 100%|██████████| 391/391 [00:37<00:00, 10.43it/s, acc=78.5, loss=0.00483]\nTest Epoch 4: 100%|██████████| 79/79 [00:03<00:00, 22.34it/s, acc=78.6, loss=0.00493]\nTrain Epoch 5: 100%|██████████| 391/391 [00:37<00:00, 10.41it/s, acc=81, loss=0.00432]  \nTest Epoch 5: 100%|██████████| 79/79 [00:03<00:00, 22.25it/s, acc=78.6, loss=0.00487]\nTrain Epoch 6: 100%|██████████| 391/391 [00:37<00:00, 10.48it/s, acc=82.4, loss=0.00401]\nTest Epoch 6: 100%|██████████| 79/79 [00:03<00:00, 21.80it/s, acc=80.6, loss=0.00463]\nTrain Epoch 7: 100%|██████████| 391/391 [00:37<00:00, 10.31it/s, acc=83.5, loss=0.00376]\nTest Epoch 7: 100%|██████████| 79/79 [00:03<00:00, 22.55it/s, acc=81.5, loss=0.00438]\nTrain Epoch 8:   1%|          | 3/391 [00:00<00:42,  9.15it/s, acc=84.8, loss=0.00337]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'cifar10_cnn_featSqueeze.pth')","metadata":{"_uuid":"4e9c994d-1616-43bc-92e0-fe20cac95966","_cell_guid":"2301ba15-6648-4866-8d04-bd78818dc218","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\ntarget_class = torch.tensor([9], dtype=torch.long, device=\"cuda\") \nmodel = model.to(\"cuda\")\nmodel.eval()\nc = 0\nfor i in range(100):\n    j = random.randint(1, 400)\n    input_image = train[j][0].unsqueeze(0).to(\"cuda\")\n    input_image = input_image.detach().clone()\n    input_image.requires_grad_(True)\n    output = model(input_image)\n    loss = -torch.nn.functional.cross_entropy(output, target_class)\n    \n    model.zero_grad()\n    loss.backward()\n    \n    with torch.no_grad():\n        input_image += 0.1 * input_image.grad.sign()\n        input_image.clamp_(0, 1)\n    input_image.grad.zero_()\n    # print(f\"Iteration {i}, Loss: {loss.item()}\")\n    a = model(input_image)\n    pred = torch.argmax(torch.nn.functional.softmax(a, dim=1)).item()\n    if pred == train[j][1]:\n        c += 1\nprint(c / 100)","metadata":{"_uuid":"2c68f8d3-bf73-4c98-a33f-55c9661f672c","_cell_guid":"ef7fa74e-b8b0-4699-a016-6570ff5c7073","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T10:45:02.507850Z","iopub.execute_input":"2025-03-09T10:45:02.508123Z","iopub.status.idle":"2025-03-09T10:45:03.222388Z","shell.execute_reply.started":"2025-03-09T10:45:02.508103Z","shell.execute_reply":"2025-03-09T10:45:03.221604Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"0.54\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}