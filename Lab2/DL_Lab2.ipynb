{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-22T17:00:31.796439Z",
          "iopub.status.busy": "2025-01-22T17:00:31.796116Z",
          "iopub.status.idle": "2025-01-22T17:00:32.061104Z",
          "shell.execute_reply": "2025-01-22T17:00:32.060388Z",
          "shell.execute_reply.started": "2025-01-22T17:00:31.796411Z"
        },
        "id": "BbXa48gk-GwW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-22T17:00:35.667907Z",
          "iopub.status.busy": "2025-01-22T17:00:35.667567Z",
          "iopub.status.idle": "2025-01-22T17:00:35.675883Z",
          "shell.execute_reply": "2025-01-22T17:00:35.674958Z",
          "shell.execute_reply.started": "2025-01-22T17:00:35.667879Z"
        },
        "id": "j_GDY8R9-GwW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Model(keras.Model):\n",
        "    def __init__(self, dropout=0.0):\n",
        "        super(Model, self).__init__()\n",
        "        self.flatten = keras.layers.Flatten()\n",
        "        self.dense1 = keras.layers.Dense(100, activation=\"relu\")\n",
        "        self.dense2 = keras.layers.Dense(100, activation=\"relu\")\n",
        "        self.dense3 = keras.layers.Dense(100, activation=\"relu\")\n",
        "        self.output_layer = keras.layers.Dense(10, activation=\"softmax\")\n",
        "        self.dropout = keras.layers.Dropout(dropout)\n",
        "        self.callbacks = []\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense3(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    def train_loop(\n",
        "        self, x_train, y_train, x_test, y_test, run_name, batch_size=32, epochs=20, loss=\"sparse_categorical_crossentropy\"\n",
        "    ):\n",
        "        self.callbacks.append(TensorBoard(log_dir=f\"./runs/{run_name}\", histogram_freq=1))\n",
        "        self.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=loss,\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        self.fit(\n",
        "            x_train,\n",
        "            y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            callbacks=self.callbacks,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-22T17:00:38.029975Z",
          "iopub.status.busy": "2025-01-22T17:00:38.029613Z",
          "iopub.status.idle": "2025-01-22T17:00:38.178812Z",
          "shell.execute_reply": "2025-01-22T17:00:38.178139Z",
          "shell.execute_reply.started": "2025-01-22T17:00:38.029946Z"
        },
        "id": "R2bV8UUF-GwW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-01-22T17:00:39.091606Z",
          "iopub.status.busy": "2025-01-22T17:00:39.091312Z",
          "iopub.status.idle": "2025-01-22T17:00:55.969927Z",
          "shell.execute_reply": "2025-01-22T17:00:55.969206Z",
          "shell.execute_reply.started": "2025-01-22T17:00:39.091584Z"
        },
        "id": "-eEp9Gj_-GwW",
        "outputId": "b987b30d-c863-4ee1-c42b-09f514c9fb7e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7088 - loss: 1.0252 - val_accuracy: 0.9361 - val_loss: 0.2174\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.2120 - val_accuracy: 0.9533 - val_loss: 0.1566\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9576 - loss: 0.1436 - val_accuracy: 0.9619 - val_loss: 0.1312\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9653 - loss: 0.1165 - val_accuracy: 0.9673 - val_loss: 0.1109\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0957 - val_accuracy: 0.9680 - val_loss: 0.1028\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0755 - val_accuracy: 0.9689 - val_loss: 0.0957\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0682 - val_accuracy: 0.9744 - val_loss: 0.0868\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0555 - val_accuracy: 0.9728 - val_loss: 0.0880\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0479 - val_accuracy: 0.9749 - val_loss: 0.0824\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0386 - val_accuracy: 0.9749 - val_loss: 0.0854\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0342 - val_accuracy: 0.9719 - val_loss: 0.0877\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0303 - val_accuracy: 0.9740 - val_loss: 0.0889\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0232 - val_accuracy: 0.9753 - val_loss: 0.0843\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0195 - val_accuracy: 0.9757 - val_loss: 0.0887\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0197 - val_accuracy: 0.9753 - val_loss: 0.0873\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0201 - val_accuracy: 0.9763 - val_loss: 0.0864\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0147 - val_accuracy: 0.9766 - val_loss: 0.0902\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0135 - val_accuracy: 0.9748 - val_loss: 0.0963\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0125 - val_accuracy: 0.9761 - val_loss: 0.0931\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0093 - val_accuracy: 0.9766 - val_loss: 0.0922\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"no-reg\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4soWOhLzBlNd"
      },
      "source": [
        "# L1 Reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFN0yz9PBm49",
        "outputId": "ac24c829-1538-41e1-b470-a9f7b456a9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_25', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7037 - loss: 1.4926 - val_accuracy: 0.9339 - val_loss: 0.5390\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.5181 - val_accuracy: 0.9499 - val_loss: 0.4474\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9543 - loss: 0.4358 - val_accuracy: 0.9601 - val_loss: 0.3963\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9621 - loss: 0.3852 - val_accuracy: 0.9621 - val_loss: 0.3669\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.3512 - val_accuracy: 0.9661 - val_loss: 0.3429\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9718 - loss: 0.3264 - val_accuracy: 0.9684 - val_loss: 0.3292\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9738 - loss: 0.3068 - val_accuracy: 0.9713 - val_loss: 0.3130\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.2938 - val_accuracy: 0.9724 - val_loss: 0.2952\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.2790 - val_accuracy: 0.9737 - val_loss: 0.2796\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.2668 - val_accuracy: 0.9742 - val_loss: 0.2743\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.2519 - val_accuracy: 0.9744 - val_loss: 0.2668\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.2480 - val_accuracy: 0.9757 - val_loss: 0.2540\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.2360 - val_accuracy: 0.9766 - val_loss: 0.2489\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.2307 - val_accuracy: 0.9762 - val_loss: 0.2476\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.2210 - val_accuracy: 0.9742 - val_loss: 0.2477\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.2198 - val_accuracy: 0.9768 - val_loss: 0.2357\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.2113 - val_accuracy: 0.9776 - val_loss: 0.2273\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.2039 - val_accuracy: 0.9718 - val_loss: 0.2363\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.2006 - val_accuracy: 0.9756 - val_loss: 0.2292\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.1997 - val_accuracy: 0.9735 - val_loss: 0.2265\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(0.0001))\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(0.0001))\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(0.0001))\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"l1-reg\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKZqOYQBESCi"
      },
      "source": [
        "# L2 reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pon0F7OERuy",
        "outputId": "a950fe0f-be4a-4d1e-f7e6-f479153b56d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_26', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7188 - loss: 1.0476 - val_accuracy: 0.9295 - val_loss: 0.2655\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9386 - loss: 0.2440 - val_accuracy: 0.9530 - val_loss: 0.1930\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9562 - loss: 0.1818 - val_accuracy: 0.9575 - val_loss: 0.1713\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.1527 - val_accuracy: 0.9654 - val_loss: 0.1490\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9722 - loss: 0.1277 - val_accuracy: 0.9689 - val_loss: 0.1361\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.1111 - val_accuracy: 0.9711 - val_loss: 0.1310\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.1057 - val_accuracy: 0.9708 - val_loss: 0.1300\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0928 - val_accuracy: 0.9744 - val_loss: 0.1194\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0873 - val_accuracy: 0.9721 - val_loss: 0.1259\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0806 - val_accuracy: 0.9750 - val_loss: 0.1181\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0741 - val_accuracy: 0.9777 - val_loss: 0.1115\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0692 - val_accuracy: 0.9774 - val_loss: 0.1119\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0667 - val_accuracy: 0.9775 - val_loss: 0.1099\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0646 - val_accuracy: 0.9774 - val_loss: 0.1116\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0617 - val_accuracy: 0.9766 - val_loss: 0.1144\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0592 - val_accuracy: 0.9772 - val_loss: 0.1125\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0610 - val_accuracy: 0.9765 - val_loss: 0.1208\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0554 - val_accuracy: 0.9775 - val_loss: 0.1138\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0518 - val_accuracy: 0.9724 - val_loss: 0.1285\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0553 - val_accuracy: 0.9780 - val_loss: 0.1126\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001))\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001))\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001))\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"l2-reg\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aic4oIqYFm8u"
      },
      "source": [
        "# Data aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "L_0kkCmMFokl"
      },
      "outputs": [],
      "source": [
        "data_augmemtation = keras.Sequential([\n",
        "    keras.layers.RandomTranslation(0.1, 0.1),\n",
        "    keras.layers.RandomRotation(0.1),\n",
        "    keras.layers.RandomZoom(0.055),\n",
        "])\n",
        "\n",
        "xtrain_aug, xtest_aug = data_augmemtation(x_train.reshape((-1, 1, 28, 28))), data_augmemtation(x_test.reshape((-1, 1, 28, 28)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Hxv9BmGe51",
        "outputId": "28f03059-1aa8-49dc-8a76-2041cb4c7116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5939 - loss: 1.2907 - val_accuracy: 0.8855 - val_loss: 0.3788\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9016 - loss: 0.3287 - val_accuracy: 0.9284 - val_loss: 0.2308\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.2057 - val_accuracy: 0.9421 - val_loss: 0.1829\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9513 - loss: 0.1599 - val_accuracy: 0.9526 - val_loss: 0.1552\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.1257 - val_accuracy: 0.9565 - val_loss: 0.1451\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1054 - val_accuracy: 0.9587 - val_loss: 0.1336\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.0918 - val_accuracy: 0.9548 - val_loss: 0.1469\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0893 - val_accuracy: 0.9630 - val_loss: 0.1246\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0728 - val_accuracy: 0.9599 - val_loss: 0.1375\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0665 - val_accuracy: 0.9618 - val_loss: 0.1283\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0568 - val_accuracy: 0.9643 - val_loss: 0.1280\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.0550 - val_accuracy: 0.9662 - val_loss: 0.1189\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0495 - val_accuracy: 0.9653 - val_loss: 0.1178\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0416 - val_accuracy: 0.9681 - val_loss: 0.1195\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0396 - val_accuracy: 0.9668 - val_loss: 0.1214\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0334 - val_accuracy: 0.9678 - val_loss: 0.1257\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0307 - val_accuracy: 0.9672 - val_loss: 0.1260\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0261 - val_accuracy: 0.9660 - val_loss: 0.1315\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0240 - val_accuracy: 0.9629 - val_loss: 0.1514\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0262 - val_accuracy: 0.9639 - val_loss: 0.1386\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.train_loop(xtrain_aug, y_train, xtest_aug, y_test, \"data-aug\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqTYjO-_fZUC"
      },
      "source": [
        "# Input noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzk-myO7fbTW",
        "outputId": "7b6de3e0-b5c5-4983-e936-12a0a09eb90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6683 - loss: 1.1362 - val_accuracy: 0.9228 - val_loss: 0.2610\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9234 - loss: 0.2559 - val_accuracy: 0.9453 - val_loss: 0.1744\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1676 - val_accuracy: 0.9598 - val_loss: 0.1297\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9660 - loss: 0.1173 - val_accuracy: 0.9635 - val_loss: 0.1162\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9735 - loss: 0.0913 - val_accuracy: 0.9669 - val_loss: 0.1124\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0649 - val_accuracy: 0.9692 - val_loss: 0.0999\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0467 - val_accuracy: 0.9684 - val_loss: 0.1057\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0351 - val_accuracy: 0.9675 - val_loss: 0.1071\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0255 - val_accuracy: 0.9702 - val_loss: 0.1026\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0169 - val_accuracy: 0.9718 - val_loss: 0.1097\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0104 - val_accuracy: 0.9728 - val_loss: 0.1053\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0075 - val_accuracy: 0.9724 - val_loss: 0.1112\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0040 - val_accuracy: 0.9734 - val_loss: 0.1119\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9741 - val_loss: 0.1184\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9745 - val_loss: 0.1222\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9740 - val_loss: 0.1233\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9738 - val_loss: 0.1267\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.4178e-04 - val_accuracy: 0.9741 - val_loss: 0.1303\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2660e-04 - val_accuracy: 0.9737 - val_loss: 0.1318\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8727e-04 - val_accuracy: 0.9738 - val_loss: 0.1326\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "noise = np.random.normal(0, 0.2, x_train.shape)\n",
        "x_train_noise = x_train + noise\n",
        "model = Model()\n",
        "model.train_loop(x_train_noise, y_train, x_test, y_test, \"input-noise\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DapVE86fo3f"
      },
      "source": [
        "# Output noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twh9SOo2fryM",
        "outputId": "d4102d33-0d19-4fba-9a7f-bbfbcf97c6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1.0000000000000002,\n",
              " array([0.01282876, 0.01282876, 0.88454118, 0.01282876, 0.01282876,\n",
              "        0.01282876, 0.01282876, 0.01282876, 0.01282876, 0.01282876]))"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "noise = abs(np.random.normal(0, 0.1, y_train.shape))\n",
        "noise = np.expand_dims(noise, 1)\n",
        "print(noise.shape)\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
        "label = np.argmax(y_train_one_hot, axis=1)\n",
        "y_train_noise = y_train_one_hot + (noise / 9)\n",
        "y_train_noise[y_train_noise > 1] = 1 - noise[:, 0]\n",
        "sum(y_train_noise[5]), y_train_noise[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRsD1soMi1Xi",
        "outputId": "b443425c-fa43-478e-c79b-88d027a6bf3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7118 - loss: 1.3113 - val_accuracy: 0.9388 - val_loss: 0.3102\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.6546 - val_accuracy: 0.9549 - val_loss: 0.2430\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9623 - loss: 0.6042 - val_accuracy: 0.9637 - val_loss: 0.2148\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9709 - loss: 0.5709 - val_accuracy: 0.9688 - val_loss: 0.1939\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.5547 - val_accuracy: 0.9721 - val_loss: 0.1936\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.5406 - val_accuracy: 0.9746 - val_loss: 0.1768\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.5264 - val_accuracy: 0.9757 - val_loss: 0.1700\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.5190 - val_accuracy: 0.9778 - val_loss: 0.1703\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.5109 - val_accuracy: 0.9781 - val_loss: 0.1613\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.5076 - val_accuracy: 0.9784 - val_loss: 0.1514\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.5009 - val_accuracy: 0.9803 - val_loss: 0.1583\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.4971 - val_accuracy: 0.9783 - val_loss: 0.1532\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.4929 - val_accuracy: 0.9793 - val_loss: 0.1542\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.4890 - val_accuracy: 0.9797 - val_loss: 0.1502\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.4849 - val_accuracy: 0.9800 - val_loss: 0.1547\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.4840 - val_accuracy: 0.9797 - val_loss: 0.1398\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.4808 - val_accuracy: 0.9797 - val_loss: 0.1456\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.4783 - val_accuracy: 0.9796 - val_loss: 0.1510\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.4769 - val_accuracy: 0.9809 - val_loss: 0.1494\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.4754 - val_accuracy: 0.9810 - val_loss: 0.1448\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.train_loop(x_train, y_train_noise, x_test, keras.utils.to_categorical(y_test, 10), \"output-noise\", batch_size=512, loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTs8Aen5GwLx"
      },
      "source": [
        "# Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEn9oa0JGvjm",
        "outputId": "b20f20cb-e915-4c0a-be2d-fb3eecdcdc8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6995 - loss: 1.0432 - val_accuracy: 0.9344 - val_loss: 0.2185\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.2075 - val_accuracy: 0.9512 - val_loss: 0.1589\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 0.1473 - val_accuracy: 0.9604 - val_loss: 0.1335\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1148 - val_accuracy: 0.9639 - val_loss: 0.1160\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9729 - loss: 0.0927 - val_accuracy: 0.9667 - val_loss: 0.1088\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0790 - val_accuracy: 0.9701 - val_loss: 0.0944\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0649 - val_accuracy: 0.9734 - val_loss: 0.0854\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0580 - val_accuracy: 0.9731 - val_loss: 0.0883\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0473 - val_accuracy: 0.9745 - val_loss: 0.0842\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0380 - val_accuracy: 0.9690 - val_loss: 0.0971\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0376 - val_accuracy: 0.9714 - val_loss: 0.0950\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0338 - val_accuracy: 0.9760 - val_loss: 0.0833\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0270 - val_accuracy: 0.9751 - val_loss: 0.0854\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0225 - val_accuracy: 0.9764 - val_loss: 0.0819\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0208 - val_accuracy: 0.9762 - val_loss: 0.0839\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0147 - val_accuracy: 0.9765 - val_loss: 0.0851\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0147 - val_accuracy: 0.9775 - val_loss: 0.0831\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0126 - val_accuracy: 0.9757 - val_loss: 0.0917\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0104 - val_accuracy: 0.9762 - val_loss: 0.0901\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0112 - val_accuracy: 0.9767 - val_loss: 0.0950\n"
          ]
        }
      ],
      "source": [
        "model = Model(dropout=0.5)\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"dropout\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4ty4WG8jvno"
      },
      "source": [
        "# Weight initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqN0kBZXjzIo"
      },
      "source": [
        "# zeroes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aCBwehcj0sq",
        "outputId": "ada4d459-ea62-4876-b81c-28a4f716167b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_31', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1082 - loss: 2.3022 - val_accuracy: 0.1135 - val_loss: 2.3013\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3011\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1132 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3010 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1131 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1127 - loss: 2.3011 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1145 - loss: 2.3010 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1123 - loss: 2.3014 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1114 - loss: 2.3013 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1130 - loss: 2.3011 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1100 - loss: 2.3016 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1121 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1120 - loss: 2.3014 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1120 - loss: 2.3014 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1106 - loss: 2.3013 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1119 - loss: 2.3011 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1103 - loss: 2.3014 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1104 - loss: 2.3015 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3007 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1129 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"zeros\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"zeros\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"zeros\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"zeroes\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0lIOFWdkGOX"
      },
      "source": [
        "# ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOZ7d8xxkHhS",
        "outputId": "cbdde3e1-b065-454e-828a-6c0c12b356b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_32', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0982 - loss: 677171.3750 - val_accuracy: 0.0982 - val_loss: 73554.5312\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1026 - loss: 57336.3398 - val_accuracy: 0.0974 - val_loss: 53327.7656\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0990 - loss: 59369.1680 - val_accuracy: 0.1010 - val_loss: 53891.8789\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0989 - loss: 49255.5508 - val_accuracy: 0.0974 - val_loss: 32417.1719\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 44181.6055 - val_accuracy: 0.1028 - val_loss: 26561.8633\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0986 - loss: 46643.9922 - val_accuracy: 0.1010 - val_loss: 39947.1992\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0998 - loss: 31843.5449 - val_accuracy: 0.0958 - val_loss: 40524.0156\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0980 - loss: 40158.4805 - val_accuracy: 0.1028 - val_loss: 29970.8730\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 29869.6250 - val_accuracy: 0.1028 - val_loss: 20782.9062\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0996 - loss: 19969.3574 - val_accuracy: 0.0980 - val_loss: 20681.1621\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1018 - loss: 25359.8887 - val_accuracy: 0.0974 - val_loss: 22562.6309\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0998 - loss: 23079.1270 - val_accuracy: 0.1028 - val_loss: 13340.1416\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0976 - loss: 15242.4092 - val_accuracy: 0.1010 - val_loss: 12272.5596\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0984 - loss: 15546.8096 - val_accuracy: 0.0982 - val_loss: 14221.4932\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0985 - loss: 12118.3096 - val_accuracy: 0.0974 - val_loss: 13182.9736\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1019 - loss: 11791.1729 - val_accuracy: 0.1010 - val_loss: 9199.3486\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 9759.0254 - val_accuracy: 0.1135 - val_loss: 9616.3877\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0999 - loss: 8698.3750 - val_accuracy: 0.0980 - val_loss: 6429.1997\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1013 - loss: 7302.0166 - val_accuracy: 0.0892 - val_loss: 4093.3896\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1020 - loss: 6198.6211 - val_accuracy: 0.0958 - val_loss: 6089.2222\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"ones\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"ones\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"ones\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"ones\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vwhCvPqkRrH"
      },
      "source": [
        "# random normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u25sh7TgkTHd",
        "outputId": "3f75bd8c-2d74-457e-ea43-a90997f259eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_33', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6250 - loss: 1.2149 - val_accuracy: 0.9151 - val_loss: 0.2817\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.2523 - val_accuracy: 0.9449 - val_loss: 0.1910\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.1801 - val_accuracy: 0.9543 - val_loss: 0.1536\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.1416 - val_accuracy: 0.9623 - val_loss: 0.1287\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.1189 - val_accuracy: 0.9650 - val_loss: 0.1160\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0934 - val_accuracy: 0.9676 - val_loss: 0.1054\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.0808 - val_accuracy: 0.9695 - val_loss: 0.1037\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0715 - val_accuracy: 0.9707 - val_loss: 0.0950\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0635 - val_accuracy: 0.9713 - val_loss: 0.1012\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0547 - val_accuracy: 0.9698 - val_loss: 0.0955\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0479 - val_accuracy: 0.9745 - val_loss: 0.0898\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0457 - val_accuracy: 0.9742 - val_loss: 0.0827\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0373 - val_accuracy: 0.9763 - val_loss: 0.0856\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0305 - val_accuracy: 0.9747 - val_loss: 0.0884\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0277 - val_accuracy: 0.9763 - val_loss: 0.0900\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0242 - val_accuracy: 0.9761 - val_loss: 0.0850\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0212 - val_accuracy: 0.9759 - val_loss: 0.0887\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0220 - val_accuracy: 0.9747 - val_loss: 0.0986\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0189 - val_accuracy: 0.9760 - val_loss: 0.0932\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0148 - val_accuracy: 0.9761 - val_loss: 0.0959\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"random-normal\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfdEhnI9kdGO"
      },
      "source": [
        "# glorot normal - xavier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N57wKyGkekM",
        "outputId": "6d5d773c-57d5-4816-dfff-c81306eee49f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_34', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6912 - loss: 1.0682 - val_accuracy: 0.9261 - val_loss: 0.2441\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9370 - loss: 0.2189 - val_accuracy: 0.9535 - val_loss: 0.1592\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1510 - val_accuracy: 0.9583 - val_loss: 0.1365\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.1123 - val_accuracy: 0.9633 - val_loss: 0.1170\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9726 - loss: 0.0933 - val_accuracy: 0.9679 - val_loss: 0.1059\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.0758 - val_accuracy: 0.9691 - val_loss: 0.1051\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0643 - val_accuracy: 0.9718 - val_loss: 0.0935\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.0575 - val_accuracy: 0.9718 - val_loss: 0.0939\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.0474 - val_accuracy: 0.9731 - val_loss: 0.0902\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0423 - val_accuracy: 0.9724 - val_loss: 0.0930\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0359 - val_accuracy: 0.9724 - val_loss: 0.0941\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0352 - val_accuracy: 0.9752 - val_loss: 0.0877\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0258 - val_accuracy: 0.9749 - val_loss: 0.0897\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0236 - val_accuracy: 0.9749 - val_loss: 0.0896\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0203 - val_accuracy: 0.9737 - val_loss: 0.0971\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0168 - val_accuracy: 0.9742 - val_loss: 0.1023\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0226 - val_accuracy: 0.9774 - val_loss: 0.0910\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0128 - val_accuracy: 0.9760 - val_loss: 0.0943\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0116 - val_accuracy: 0.9750 - val_loss: 0.1002\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0074 - val_accuracy: 0.9764 - val_loss: 0.0988\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"glorot_normal\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"glorot_normal\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"glorot_normal\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"glorot-normal\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0z6PAjTknQ3"
      },
      "source": [
        "# he normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvnDQ7A5kog4",
        "outputId": "98724550-7650-49a9-cd99-a77e37d0484f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_35', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7149 - loss: 0.9430 - val_accuracy: 0.9363 - val_loss: 0.2118\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.1879 - val_accuracy: 0.9546 - val_loss: 0.1508\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1344 - val_accuracy: 0.9659 - val_loss: 0.1130\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0970 - val_accuracy: 0.9655 - val_loss: 0.1148\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9738 - loss: 0.0858 - val_accuracy: 0.9685 - val_loss: 0.0967\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0690 - val_accuracy: 0.9740 - val_loss: 0.0868\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0538 - val_accuracy: 0.9735 - val_loss: 0.0885\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0476 - val_accuracy: 0.9726 - val_loss: 0.0876\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0425 - val_accuracy: 0.9755 - val_loss: 0.0798\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0367 - val_accuracy: 0.9743 - val_loss: 0.0840\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0286 - val_accuracy: 0.9758 - val_loss: 0.0823\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0264 - val_accuracy: 0.9762 - val_loss: 0.0822\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0227 - val_accuracy: 0.9748 - val_loss: 0.0835\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0183 - val_accuracy: 0.9774 - val_loss: 0.0765\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0134 - val_accuracy: 0.9756 - val_loss: 0.0929\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0137 - val_accuracy: 0.9760 - val_loss: 0.0890\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0111 - val_accuracy: 0.9755 - val_loss: 0.0889\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0108 - val_accuracy: 0.9774 - val_loss: 0.0872\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0114 - val_accuracy: 0.9762 - val_loss: 0.0925\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0132 - val_accuracy: 0.9767 - val_loss: 0.0927\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"he-normal\", batch_size=512)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30840,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
