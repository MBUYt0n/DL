{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-22T17:00:31.796439Z",
          "iopub.status.busy": "2025-01-22T17:00:31.796116Z",
          "iopub.status.idle": "2025-01-22T17:00:32.061104Z",
          "shell.execute_reply": "2025-01-22T17:00:32.060388Z",
          "shell.execute_reply.started": "2025-01-22T17:00:31.796411Z"
        },
        "id": "BbXa48gk-GwW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-22T17:00:35.667907Z",
          "iopub.status.busy": "2025-01-22T17:00:35.667567Z",
          "iopub.status.idle": "2025-01-22T17:00:35.675883Z",
          "shell.execute_reply": "2025-01-22T17:00:35.674958Z",
          "shell.execute_reply.started": "2025-01-22T17:00:35.667879Z"
        },
        "id": "j_GDY8R9-GwW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Model(keras.Model):\n",
        "    def __init__(self, dropout=0.0):\n",
        "        super(Model, self).__init__()\n",
        "        self.flatten = keras.layers.Flatten()\n",
        "        self.dense1 = keras.layers.Dense(100, activation=\"relu\")\n",
        "        self.dense2 = keras.layers.Dense(100, activation=\"relu\")\n",
        "        self.dense3 = keras.layers.Dense(100, activation=\"relu\")\n",
        "        self.output_layer = keras.layers.Dense(10, activation=\"softmax\")\n",
        "        self.dropout = keras.layers.Dropout(dropout)\n",
        "        self.callbacks = []\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.dense3(x)\n",
        "        x = self.dropout(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "    def train_loop(\n",
        "        self, x_train, y_train, x_test, y_test, run_name, batch_size=32, epochs=20, loss=\"sparse_categorical_crossentropy\"\n",
        "    ):\n",
        "        self.callbacks.append(TensorBoard(log_dir=f\"./runs/{run_name}\", histogram_freq=1))\n",
        "        self.compile(\n",
        "            optimizer=\"adam\",\n",
        "            loss=loss,\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        self.fit(\n",
        "            x_train,\n",
        "            y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            callbacks=self.callbacks,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-01-22T17:00:38.029975Z",
          "iopub.status.busy": "2025-01-22T17:00:38.029613Z",
          "iopub.status.idle": "2025-01-22T17:00:38.178812Z",
          "shell.execute_reply": "2025-01-22T17:00:38.178139Z",
          "shell.execute_reply.started": "2025-01-22T17:00:38.029946Z"
        },
        "id": "R2bV8UUF-GwW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-01-22T17:00:39.091606Z",
          "iopub.status.busy": "2025-01-22T17:00:39.091312Z",
          "iopub.status.idle": "2025-01-22T17:00:55.969927Z",
          "shell.execute_reply": "2025-01-22T17:00:55.969206Z",
          "shell.execute_reply.started": "2025-01-22T17:00:39.091584Z"
        },
        "id": "-eEp9Gj_-GwW",
        "outputId": "b987b30d-c863-4ee1-c42b-09f514c9fb7e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6973 - loss: 1.0633 - val_accuracy: 0.9332 - val_loss: 0.2343\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9361 - loss: 0.2238 - val_accuracy: 0.9470 - val_loss: 0.1798\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9509 - loss: 0.1641 - val_accuracy: 0.9561 - val_loss: 0.1509\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.1236 - val_accuracy: 0.9657 - val_loss: 0.1148\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9695 - loss: 0.1025 - val_accuracy: 0.9637 - val_loss: 0.1181\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0821 - val_accuracy: 0.9729 - val_loss: 0.0901\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0638 - val_accuracy: 0.9677 - val_loss: 0.1001\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0583 - val_accuracy: 0.9742 - val_loss: 0.0835\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0480 - val_accuracy: 0.9747 - val_loss: 0.0804\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0439 - val_accuracy: 0.9774 - val_loss: 0.0763\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0360 - val_accuracy: 0.9760 - val_loss: 0.0757\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0321 - val_accuracy: 0.9762 - val_loss: 0.0807\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0283 - val_accuracy: 0.9769 - val_loss: 0.0799\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0260 - val_accuracy: 0.9773 - val_loss: 0.0786\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0215 - val_accuracy: 0.9777 - val_loss: 0.0757\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0173 - val_accuracy: 0.9777 - val_loss: 0.0789\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0151 - val_accuracy: 0.9749 - val_loss: 0.0911\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0134 - val_accuracy: 0.9759 - val_loss: 0.0919\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0105 - val_accuracy: 0.9768 - val_loss: 0.0849\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0119 - val_accuracy: 0.9762 - val_loss: 0.0915\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"no-reg\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4soWOhLzBlNd"
      },
      "source": [
        "# L1 Reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFN0yz9PBm49",
        "outputId": "ac24c829-1538-41e1-b470-a9f7b456a9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_42', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 1.4510 - val_accuracy: 0.9350 - val_loss: 0.5445\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.5201 - val_accuracy: 0.9457 - val_loss: 0.4528\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9535 - loss: 0.4345 - val_accuracy: 0.9559 - val_loss: 0.4068\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.3907 - val_accuracy: 0.9630 - val_loss: 0.3676\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.3571 - val_accuracy: 0.9662 - val_loss: 0.3456\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.3296 - val_accuracy: 0.9662 - val_loss: 0.3277\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.3158 - val_accuracy: 0.9692 - val_loss: 0.3130\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.2935 - val_accuracy: 0.9714 - val_loss: 0.3023\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.2812 - val_accuracy: 0.9715 - val_loss: 0.2877\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.2684 - val_accuracy: 0.9718 - val_loss: 0.2799\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.2586 - val_accuracy: 0.9733 - val_loss: 0.2722\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.2483 - val_accuracy: 0.9766 - val_loss: 0.2614\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.2402 - val_accuracy: 0.9740 - val_loss: 0.2586\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.2378 - val_accuracy: 0.9758 - val_loss: 0.2522\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.2257 - val_accuracy: 0.9760 - val_loss: 0.2418\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.2202 - val_accuracy: 0.9771 - val_loss: 0.2328\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.2136 - val_accuracy: 0.9712 - val_loss: 0.2464\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.2096 - val_accuracy: 0.9758 - val_loss: 0.2326\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.2011 - val_accuracy: 0.9742 - val_loss: 0.2338\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.1999 - val_accuracy: 0.9765 - val_loss: 0.2205\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(0.0001))\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(0.0001))\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(0.0001))\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"l1-reg\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKZqOYQBESCi"
      },
      "source": [
        "# L2 reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pon0F7OERuy",
        "outputId": "a950fe0f-be4a-4d1e-f7e6-f479153b56d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_43', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7154 - loss: 1.0441 - val_accuracy: 0.9324 - val_loss: 0.2639\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.2457 - val_accuracy: 0.9527 - val_loss: 0.1960\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1884 - val_accuracy: 0.9597 - val_loss: 0.1723\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1581 - val_accuracy: 0.9667 - val_loss: 0.1468\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.1293 - val_accuracy: 0.9637 - val_loss: 0.1502\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9761 - loss: 0.1181 - val_accuracy: 0.9701 - val_loss: 0.1277\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.1071 - val_accuracy: 0.9706 - val_loss: 0.1306\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0988 - val_accuracy: 0.9712 - val_loss: 0.1268\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0884 - val_accuracy: 0.9727 - val_loss: 0.1215\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0868 - val_accuracy: 0.9757 - val_loss: 0.1155\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0837 - val_accuracy: 0.9771 - val_loss: 0.1123\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0715 - val_accuracy: 0.9781 - val_loss: 0.1086\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0710 - val_accuracy: 0.9747 - val_loss: 0.1215\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0684 - val_accuracy: 0.9764 - val_loss: 0.1132\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0628 - val_accuracy: 0.9764 - val_loss: 0.1114\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0603 - val_accuracy: 0.9779 - val_loss: 0.1122\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0590 - val_accuracy: 0.9779 - val_loss: 0.1146\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0578 - val_accuracy: 0.9779 - val_loss: 0.1123\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0555 - val_accuracy: 0.9780 - val_loss: 0.1146\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0521 - val_accuracy: 0.9767 - val_loss: 0.1190\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001))\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001))\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.0001))\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"l2-reg\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aic4oIqYFm8u"
      },
      "source": [
        "# Data aug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "L_0kkCmMFokl"
      },
      "outputs": [],
      "source": [
        "data_augmemtation = keras.Sequential([\n",
        "    keras.layers.RandomTranslation(0.1, 0.1),\n",
        "    keras.layers.RandomRotation(0.1),\n",
        "    keras.layers.RandomZoom(0.055),\n",
        "])\n",
        "\n",
        "xtrain_aug, xtest_aug = data_augmemtation(x_train.reshape((-1, 1, 28, 28))), data_augmemtation(x_test.reshape((-1, 1, 28, 28)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9Hxv9BmGe51",
        "outputId": "28f03059-1aa8-49dc-8a76-2041cb4c7116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6058 - loss: 1.2657 - val_accuracy: 0.8918 - val_loss: 0.3616\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.3142 - val_accuracy: 0.9292 - val_loss: 0.2357\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.2032 - val_accuracy: 0.9436 - val_loss: 0.1840\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.1636 - val_accuracy: 0.9513 - val_loss: 0.1611\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1330 - val_accuracy: 0.9540 - val_loss: 0.1510\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1121 - val_accuracy: 0.9551 - val_loss: 0.1448\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9701 - loss: 0.0974 - val_accuracy: 0.9591 - val_loss: 0.1435\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0810 - val_accuracy: 0.9603 - val_loss: 0.1336\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.0757 - val_accuracy: 0.9610 - val_loss: 0.1305\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.0628 - val_accuracy: 0.9623 - val_loss: 0.1262\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0590 - val_accuracy: 0.9658 - val_loss: 0.1197\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0497 - val_accuracy: 0.9638 - val_loss: 0.1218\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0467 - val_accuracy: 0.9644 - val_loss: 0.1176\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0378 - val_accuracy: 0.9624 - val_loss: 0.1325\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0371 - val_accuracy: 0.9627 - val_loss: 0.1407\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0320 - val_accuracy: 0.9674 - val_loss: 0.1217\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0271 - val_accuracy: 0.9649 - val_loss: 0.1369\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0299 - val_accuracy: 0.9643 - val_loss: 0.1284\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0224 - val_accuracy: 0.9689 - val_loss: 0.1326\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0247 - val_accuracy: 0.9672 - val_loss: 0.1375\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.train_loop(xtrain_aug, y_train, xtest_aug, y_test, \"data-aug\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqTYjO-_fZUC"
      },
      "source": [
        "# Input noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzk-myO7fbTW",
        "outputId": "7b6de3e0-b5c5-4983-e936-12a0a09eb90b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 1.0902 - val_accuracy: 0.9199 - val_loss: 0.2614\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9238 - loss: 0.2554 - val_accuracy: 0.9512 - val_loss: 0.1681\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9502 - loss: 0.1718 - val_accuracy: 0.9589 - val_loss: 0.1388\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.1295 - val_accuracy: 0.9617 - val_loss: 0.1236\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.0953 - val_accuracy: 0.9666 - val_loss: 0.1082\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0727 - val_accuracy: 0.9679 - val_loss: 0.1019\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0565 - val_accuracy: 0.9700 - val_loss: 0.1014\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0370 - val_accuracy: 0.9695 - val_loss: 0.1084\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.0283 - val_accuracy: 0.9712 - val_loss: 0.1039\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0179 - val_accuracy: 0.9718 - val_loss: 0.1090\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0130 - val_accuracy: 0.9711 - val_loss: 0.1126\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0093 - val_accuracy: 0.9725 - val_loss: 0.1179\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0051 - val_accuracy: 0.9729 - val_loss: 0.1182\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0029 - val_accuracy: 0.9733 - val_loss: 0.1174\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9732 - val_loss: 0.1206\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9738 - val_loss: 0.1242\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9739 - val_loss: 0.1261\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1266e-04 - val_accuracy: 0.9729 - val_loss: 0.1292\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.5765e-04 - val_accuracy: 0.9732 - val_loss: 0.1314\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4026e-04 - val_accuracy: 0.9736 - val_loss: 0.1351\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "noise = np.random.normal(0, 0.2, x_train.shape)\n",
        "x_train_noise = x_train + noise\n",
        "model = Model()\n",
        "model.train_loop(x_train_noise, y_train, x_test, y_test, \"input-noise\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DapVE86fo3f"
      },
      "source": [
        "# Output noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twh9SOo2fryM",
        "outputId": "d4102d33-0d19-4fba-9a7f-bbfbcf97c6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1.0000000000000002,\n",
              " array([0.00941023, 0.00941023, 0.91530795, 0.00941023, 0.00941023,\n",
              "        0.00941023, 0.00941023, 0.00941023, 0.00941023, 0.00941023]))"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "noise = abs(np.random.normal(0, 0.1, y_train.shape))\n",
        "noise = np.expand_dims(noise, 1)\n",
        "print(noise.shape)\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
        "label = np.argmax(y_train_one_hot, axis=1)\n",
        "y_train_noise = y_train_one_hot + (noise / 9)\n",
        "y_train_noise[y_train_noise > 1] = 1 - noise[:, 0]\n",
        "sum(y_train_noise[5]), y_train_noise[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRsD1soMi1Xi",
        "outputId": "b443425c-fa43-478e-c79b-88d027a6bf3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6924 - loss: 1.2810 - val_accuracy: 0.9378 - val_loss: 0.3027\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.6632 - val_accuracy: 0.9551 - val_loss: 0.2429\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.6069 - val_accuracy: 0.9641 - val_loss: 0.2138\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.5803 - val_accuracy: 0.9678 - val_loss: 0.2020\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9752 - loss: 0.5596 - val_accuracy: 0.9696 - val_loss: 0.1940\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.5416 - val_accuracy: 0.9733 - val_loss: 0.1758\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.5334 - val_accuracy: 0.9772 - val_loss: 0.1685\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.5225 - val_accuracy: 0.9776 - val_loss: 0.1612\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.5139 - val_accuracy: 0.9781 - val_loss: 0.1568\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.5069 - val_accuracy: 0.9783 - val_loss: 0.1566\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.5008 - val_accuracy: 0.9785 - val_loss: 0.1546\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.4973 - val_accuracy: 0.9786 - val_loss: 0.1559\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9936 - loss: 0.4923 - val_accuracy: 0.9797 - val_loss: 0.1527\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.4895 - val_accuracy: 0.9794 - val_loss: 0.1501\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.4852 - val_accuracy: 0.9812 - val_loss: 0.1442\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.4848 - val_accuracy: 0.9811 - val_loss: 0.1459\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.4801 - val_accuracy: 0.9815 - val_loss: 0.1520\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.4788 - val_accuracy: 0.9818 - val_loss: 0.1448\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.4758 - val_accuracy: 0.9809 - val_loss: 0.1556\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.4752 - val_accuracy: 0.9808 - val_loss: 0.1556\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.train_loop(x_train, y_train_noise, x_test, keras.utils.to_categorical(y_test, 10), \"output-noise\", batch_size=512, loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTs8Aen5GwLx"
      },
      "source": [
        "# Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEn9oa0JGvjm",
        "outputId": "b20f20cb-e915-4c0a-be2d-fb3eecdcdc8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6897 - loss: 1.0618 - val_accuracy: 0.9250 - val_loss: 0.2506\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 0.2264 - val_accuracy: 0.9505 - val_loss: 0.1661\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9539 - loss: 0.1587 - val_accuracy: 0.9594 - val_loss: 0.1343\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.1239 - val_accuracy: 0.9641 - val_loss: 0.1167\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.0985 - val_accuracy: 0.9644 - val_loss: 0.1123\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0827 - val_accuracy: 0.9695 - val_loss: 0.0985\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0694 - val_accuracy: 0.9694 - val_loss: 0.0996\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0609 - val_accuracy: 0.9723 - val_loss: 0.0913\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0506 - val_accuracy: 0.9739 - val_loss: 0.0875\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0431 - val_accuracy: 0.9752 - val_loss: 0.0822\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0370 - val_accuracy: 0.9740 - val_loss: 0.0841\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0327 - val_accuracy: 0.9735 - val_loss: 0.0830\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0307 - val_accuracy: 0.9752 - val_loss: 0.0838\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0252 - val_accuracy: 0.9747 - val_loss: 0.0825\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0217 - val_accuracy: 0.9754 - val_loss: 0.0858\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0183 - val_accuracy: 0.9760 - val_loss: 0.0876\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0184 - val_accuracy: 0.9769 - val_loss: 0.0861\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0127 - val_accuracy: 0.9766 - val_loss: 0.0814\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0127 - val_accuracy: 0.9748 - val_loss: 0.0943\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0105 - val_accuracy: 0.9770 - val_loss: 0.0910\n"
          ]
        }
      ],
      "source": [
        "model = Model(dropout=0.5)\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"dropout\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4ty4WG8jvno"
      },
      "source": [
        "# Weight initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqN0kBZXjzIo"
      },
      "source": [
        "# zeroes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aCBwehcj0sq",
        "outputId": "ada4d459-ea62-4876-b81c-28a4f716167b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_48', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1094 - loss: 2.3022 - val_accuracy: 0.1135 - val_loss: 2.3014\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1142 - loss: 2.3013 - val_accuracy: 0.1135 - val_loss: 2.3011\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1110 - loss: 2.3014 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1113 - loss: 2.3013 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1114 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1131 - loss: 2.3008 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1120 - loss: 2.3010 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1126 - loss: 2.3011 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1113 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1134 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1128 - loss: 2.3013 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1129 - loss: 2.3013 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1146 - loss: 2.3008 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1148 - loss: 2.3011 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1122 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1128 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1123 - loss: 2.3013 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1116 - loss: 2.3012 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1145 - loss: 2.3007 - val_accuracy: 0.1135 - val_loss: 2.3010\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1135 - loss: 2.3009 - val_accuracy: 0.1135 - val_loss: 2.3010\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"zeros\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"zeros\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"zeros\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"zeroes\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0lIOFWdkGOX"
      },
      "source": [
        "# ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOZ7d8xxkHhS",
        "outputId": "cbdde3e1-b065-454e-828a-6c0c12b356b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_49', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 306517.0938 - val_accuracy: 0.0980 - val_loss: 36937.7383\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0979 - loss: 45149.6133 - val_accuracy: 0.0980 - val_loss: 45518.1172\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 41890.2266 - val_accuracy: 0.0982 - val_loss: 57367.5195\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 42452.5859 - val_accuracy: 0.0892 - val_loss: 70600.1562\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0988 - loss: 34516.7578 - val_accuracy: 0.0892 - val_loss: 30001.2070\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0974 - loss: 26430.0996 - val_accuracy: 0.1135 - val_loss: 22998.5449\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0958 - loss: 27661.1543 - val_accuracy: 0.0980 - val_loss: 21335.7070\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0973 - loss: 19508.1094 - val_accuracy: 0.1009 - val_loss: 19128.7832\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1016 - loss: 14088.6152 - val_accuracy: 0.1009 - val_loss: 15057.3906\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0972 - loss: 12877.6084 - val_accuracy: 0.0982 - val_loss: 8884.9092\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0973 - loss: 8540.5801 - val_accuracy: 0.1032 - val_loss: 13114.4404\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1016 - loss: 8527.7637 - val_accuracy: 0.1010 - val_loss: 8445.7725\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 7752.4614 - val_accuracy: 0.1010 - val_loss: 8351.1367\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1025 - loss: 5994.2998 - val_accuracy: 0.0980 - val_loss: 5124.3691\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1022 - loss: 4138.5439 - val_accuracy: 0.0980 - val_loss: 5457.9487\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 4091.6362 - val_accuracy: 0.0974 - val_loss: 4166.9448\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1017 - loss: 3925.4502 - val_accuracy: 0.1028 - val_loss: 1831.8622\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0967 - loss: 1985.5562 - val_accuracy: 0.1009 - val_loss: 1682.1240\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1001 - loss: 2253.4351 - val_accuracy: 0.1032 - val_loss: 1279.8293\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1006 - loss: 1529.3247 - val_accuracy: 0.0974 - val_loss: 1404.3680\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"ones\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"ones\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"ones\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"ones\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vwhCvPqkRrH"
      },
      "source": [
        "# random normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u25sh7TgkTHd",
        "outputId": "3f75bd8c-2d74-457e-ea43-a90997f259eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_50', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6222 - loss: 1.2354 - val_accuracy: 0.9243 - val_loss: 0.2658\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.2477 - val_accuracy: 0.9442 - val_loss: 0.1957\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.1806 - val_accuracy: 0.9501 - val_loss: 0.1653\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1401 - val_accuracy: 0.9620 - val_loss: 0.1281\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9657 - loss: 0.1175 - val_accuracy: 0.9638 - val_loss: 0.1162\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.0980 - val_accuracy: 0.9675 - val_loss: 0.1068\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9752 - loss: 0.0842 - val_accuracy: 0.9686 - val_loss: 0.1025\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0743 - val_accuracy: 0.9733 - val_loss: 0.0944\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0639 - val_accuracy: 0.9733 - val_loss: 0.0894\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0578 - val_accuracy: 0.9718 - val_loss: 0.0955\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0493 - val_accuracy: 0.9739 - val_loss: 0.0864\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0435 - val_accuracy: 0.9728 - val_loss: 0.0928\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0374 - val_accuracy: 0.9741 - val_loss: 0.0911\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9898 - loss: 0.0337 - val_accuracy: 0.9760 - val_loss: 0.0859\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0277 - val_accuracy: 0.9775 - val_loss: 0.0815\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0295 - val_accuracy: 0.9729 - val_loss: 0.1011\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0228 - val_accuracy: 0.9759 - val_loss: 0.0882\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0180 - val_accuracy: 0.9748 - val_loss: 0.0926\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0162 - val_accuracy: 0.9781 - val_loss: 0.0899\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0164 - val_accuracy: 0.9768 - val_loss: 0.0903\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"random-normal\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfdEhnI9kdGO"
      },
      "source": [
        "# glorot normal - xavier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N57wKyGkekM",
        "outputId": "6d5d773c-57d5-4816-dfff-c81306eee49f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_51', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7028 - loss: 1.0594 - val_accuracy: 0.9356 - val_loss: 0.2187\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.2167 - val_accuracy: 0.9528 - val_loss: 0.1613\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9564 - loss: 0.1455 - val_accuracy: 0.9610 - val_loss: 0.1269\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.1044 - val_accuracy: 0.9663 - val_loss: 0.1076\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0837 - val_accuracy: 0.9706 - val_loss: 0.0962\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0744 - val_accuracy: 0.9710 - val_loss: 0.0985\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0627 - val_accuracy: 0.9731 - val_loss: 0.0922\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.0536 - val_accuracy: 0.9710 - val_loss: 0.0943\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.0464 - val_accuracy: 0.9734 - val_loss: 0.0877\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0377 - val_accuracy: 0.9732 - val_loss: 0.0919\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0344 - val_accuracy: 0.9704 - val_loss: 0.0948\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0293 - val_accuracy: 0.9735 - val_loss: 0.0916\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0260 - val_accuracy: 0.9755 - val_loss: 0.0867\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0212 - val_accuracy: 0.9744 - val_loss: 0.0908\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0200 - val_accuracy: 0.9728 - val_loss: 0.0981\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0155 - val_accuracy: 0.9741 - val_loss: 0.0942\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0124 - val_accuracy: 0.9755 - val_loss: 0.0936\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0119 - val_accuracy: 0.9751 - val_loss: 0.1040\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0106 - val_accuracy: 0.9742 - val_loss: 0.1014\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0166 - val_accuracy: 0.9749 - val_loss: 0.0991\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"glorot_normal\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"glorot_normal\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"glorot_normal\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"glorot-normal\", batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0z6PAjTknQ3"
      },
      "source": [
        "# he normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvnDQ7A5kog4",
        "outputId": "98724550-7650-49a9-cd99-a77e37d0484f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/shusrith/projects/torch/lib/python3.12/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'model_52', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7218 - loss: 0.9906 - val_accuracy: 0.9356 - val_loss: 0.2105\n",
            "Epoch 2/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.1914 - val_accuracy: 0.9561 - val_loss: 0.1562\n",
            "Epoch 3/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.1384 - val_accuracy: 0.9651 - val_loss: 0.1179\n",
            "Epoch 4/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.1032 - val_accuracy: 0.9672 - val_loss: 0.1080\n",
            "Epoch 5/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9758 - loss: 0.0814 - val_accuracy: 0.9655 - val_loss: 0.1160\n",
            "Epoch 6/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0697 - val_accuracy: 0.9742 - val_loss: 0.0872\n",
            "Epoch 7/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.0611 - val_accuracy: 0.9708 - val_loss: 0.0912\n",
            "Epoch 8/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0499 - val_accuracy: 0.9742 - val_loss: 0.0816\n",
            "Epoch 9/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0402 - val_accuracy: 0.9738 - val_loss: 0.0839\n",
            "Epoch 10/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0367 - val_accuracy: 0.9763 - val_loss: 0.0797\n",
            "Epoch 11/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0331 - val_accuracy: 0.9769 - val_loss: 0.0761\n",
            "Epoch 12/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0247 - val_accuracy: 0.9772 - val_loss: 0.0760\n",
            "Epoch 13/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0220 - val_accuracy: 0.9785 - val_loss: 0.0774\n",
            "Epoch 14/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0185 - val_accuracy: 0.9765 - val_loss: 0.0820\n",
            "Epoch 15/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0180 - val_accuracy: 0.9764 - val_loss: 0.0802\n",
            "Epoch 16/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0146 - val_accuracy: 0.9769 - val_loss: 0.0833\n",
            "Epoch 17/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0139 - val_accuracy: 0.9747 - val_loss: 0.0911\n",
            "Epoch 18/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0144 - val_accuracy: 0.9763 - val_loss: 0.0885\n",
            "Epoch 19/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0100 - val_accuracy: 0.9758 - val_loss: 0.0901\n",
            "Epoch 20/20\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0079 - val_accuracy: 0.9777 - val_loss: 0.0885\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "model.dense1 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "model.dense2 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "model.dense3 = keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
        "model.train_loop(x_train, y_train, x_test, y_test, \"he-normal\", batch_size=512)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30840,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
